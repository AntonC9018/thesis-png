\documentclass[a4paper,12pt]{report}
\usepackage{config}

% Description
\newcommand{\authorName}{CURMANSCHII Anton}
\newcommand{\thesisTitle}{PNG}
\newcommand{\uniGroupName}{IA1901}
\newcommand{\thesisType}{master}
\newcommand{\programulDeStudii}{master}
\newcommand{\identificatorulCursului}{0613.5 Informatică aplicată}

% Hardcoded for now
\newcommand{\anexeCount}{20}
\newcommand{\conferencesList}{SESIUNEA NAŢIONALĂ CU PARTICIPARE INTERNAȚIONALĂ DE COMUNICĂRI ŞTIINŢIFICE STUDENŢEŞTI, EDIŢIA A XXVIII-A}

\begin{document}

\input{foaie_de_titlu}

\clearpage
\tableofcontents

\clearpage
\unnumberedChapter{Lista Abrevierelor}
\begin{acronym}
  \acro{CI/CD}{Continuous Integration / Continuous Delivery}
  \acro{GUI}{Graphical User Interface}
  \acro{PNG}{Portable Network Graphics}
  \acro{I/O}{Input/Output}
  \acro{MVP}{Produs Minim Viabil}
  \acro{ICC}{International Color Consortium}
  \acro{WSL}{Windows Subsystem for Linux}
  \acro{CRC}{Cyclic Redundancy Check}
\end{acronym}


\clearpage
\unnumberedChapter{Adnotare}

\textbf{la teza de \thesisType ``\thesisTitle'', a studentului \authorName{}, grupa \uniGroupName{}, programul de studii \programulDeStudii.}

\textbf{Structura tezei.}
Teza constă din: Introducere, \total{num_chapters} capitole, Concluzii generale și recomandări, Bibliografie \bibliographyEntryCount{} titluri.
Textul de bază cuprinde \usefulPageCount{} de pagini și \anexeCount{} de anexe.

\textbf{Cuvinte-cheie:}
\textit{\ac{PNG}, \ac{Zlib}, \ac{Deflate}, format de fișier, arbore sintactic, aplicație pentru vizualizare.}

\textbf{Actualitatea.}

\ac{PNG} este un format de imagini folosit pe scară largă pe Internet,
în dezoltarea aplicațiilor grafice, precum și în alte diverse domenii.
Înțelegerea structurii formatului poate fi utilă pentru a-l putea extinde, 
a-l utiliza într-un mod mai eficient și acesta poate servi drept referință pentru 
crearea unor formate noi.

\textbf{Scopul și obiectivele cercetării}.

Lucrarea de față are scopul educațional -- să facă cunoștința cu structura formatului \ac{PNG}.
Obiectivele tezei constă în explorarea formatului creând o aplicație grafică de vizualizare.

Scopul tezei explicit \textit{nu constă} în afișarea imaginii pe ecran,
nici nu în generarea unei imagini în formatul PNG,
focusând anume la structura formatului.

\textbf{Rezultatele preconizate și obținute} rezumă în: 
(1) studierea și înțelegerea formatului \ac{PNG} și a formaturilor de comprimare asociate 
(2) implementarea unui parser în cod
(3) implementarea unei aplicații grafice pe baza parser-ului.

\textbf{Problemele importante rezolvate} sunt: înțelegerea slabă a formatului \ac{PNG}.

\textbf{Valoarea aplicativă.} Ca rezultat a fost implementată o aplicație care poate fi folosită pentru vizualizare a formatului \ac{PNG}.

Rezultatele obținute au fost raportate la Conferința \textbf{\conferencesList}.

% I think this one's required to be capitalized.
\unnumberedChapter{INTRODUCERE}

\markpage{usefulStuffBegin}

\textbf{Actualitatea și importanța temei.}

Formatul \ac{PNG} este utilizat pe scară largă în numeroase domenii, incluzând majoritatea aplicațiilor
web, aplicații grafice care salvează sau încarcă imagini din fișiere, precum și în dezvoltarea de jocuri.
\ac{PNG} este un format adaptiv și extensibil, având o structură băzată pe chunk-uri, versionate separat unul
de altul. Formatul include, de asemenea, mecanisme pentru asigurarea integrității datelor, precum
octeții elementului \ac{CRC}.

Reieșind din toate acestea, formatul \ac{PNG} merită să se învețe pentru a manipula eficient fișierele de
acest format, pentru a putea extinde formatul prin niște chunk-uri personalizate, și pentru a afla despre
metodele de asigurare a integrității, precum și despre algoritmii de comprimare folosite ca parte din \ac{PNG}
(Zlib). Aceste idei pot ajuta și la crearea unor formate noi de fișier, nu neapărat de imagine.

\textbf{Scopul și obiectivele.}

Lucrarea de față are scopul educațional -- să facă cunoștința cu structura formatului \ac{PNG} și a
formatului integrat de comprimare \ac{Zlib}.
Pentru aceasta s-a decis să creeze o interfață grafică care
să permită explorarea vizuală a formatului \ac{PNG},
creând un parser și oarecare alte instrumente necesare în proces.


\textbf{Suportul metodologic și tehnologic.}

Structura formatului \ac{PNG} și a formaturilor de comprimare integrate \ac{Zlib} și Deflate
a fost studiată din specificațiile acestora \cite{png_spec} \cite{zlib_spec} \cite{deflate_spec}.
Programul a fost implementat în limbajul de programare Zig \cite{zig} care a fost învățat prin documentație.
Pentru implementarea formatului Deflate ca referință a fost într-o măsură scăzută folosit codul librăriei uzlib \cite{gzip_impl}.
A fost folosită librăria Raylib \cite{raylib} drept librăria grafică.

Deoarece a fost luată abordarea explorativă la dezvoltarea aplicației,
aproape n-au fost folosite referințe externe,
fie coduri din diferite proiecte, alte lucrări științifice, sau cărți.
Pentru a crea aplicația ajung documentele de specificație a formaturilor necesare,
și o modalitate de a genera sau încărca niște imagini \ac{PNG}
pentru verificarea corectitudinii întregului program,
însă pentru aceasta poate fi folosit tocmai Paint care este prezent pe orice sistem Windows.

\textbf{Noutatea stiințifică/originalitatea.}

Cu toate că există mai multe librării \ac{PNG},
scopul aplicației dezvoltate în contextul acestei teze diferă de scopul librăriilor \ac{PNG} obișnuite,
care este reprezentarea unei imagini pe ecran,
dar nu explorarea formatului de fișier sau construirea arborelui sintactic.
Teza explicit nu are scopul de a afișa imaginea pe ecran.

\textbf{Valoarea aplicativă.}

Aplicația obținută poate fi folosită pentru a-și face cunoștința cu formatul de fișier \ac{PNG}.

Cu toate acestea, scopul principal al lucrării constă
în partea educațională și practică a acesteia pentru student,
iar aplicația este doar produsul primit în urma implementării a codurilor necesare.
Partea educațională și practică include următoarele puncte:
\begin{itemize}
    \item Experiența adunată în procesul rezolvării problemelor întâlnite;
    \item Înțelegerea formatului de fișier \ac{PNG};
    \item
        Înțelegerea formaturilor de comprimare asociate,
        și în particular experiența de implementare a acestor formaturi;
    \item Folosirea arborilor sintactice pentru a realiza partea grafică a aplicației.
\end{itemize}

Toate acestea vor avea valoare în munca profesională a sudentului în viitor.


\textbf{Sumarul tezei.}

Primul capitol, \nameref{intro_chapter_title}, aduce informații generale.
Al doilea capitol, \nameref{architecture_chapter_title}, concretizează cerințele.
Al treilea capitol, \nameref{implementation_chapter_title}, urmează implementarea.


\chapter{Capitol introducere}\label{intro_chapter_title}

\chapterConclusionSection{intro_chapter_title}


\chapter{Arhitectura Aplicației}\label{architecture_chapter_title}

\chapterConclusionSection{architecture_chapter_title}


\chapter{Implementarea Sistemului}\label{implementation_chapter_title}

În continuare, se va prezenta implementarea unui decoder \ac{PNG} care va fi folosit pentru
a vizualiza formatul \ac{PNG} printr-o aplicație \ac{GUI}.
Decoderul va fi implementat în limbajul de programare Zig\cite{zig}
după specificația \ac{PNG}, versiunea 1.2\cite{png_spec}.
Interfața grafică va fi implementată folosind Raylib\cite{raylib}, tot în Zig.

Pentru a facilita interacțiunea cu fluxuri de date și a crea o abstracție în acest sens,
a fost dezvoltată o mică bibliotecă.
Experiența anterioară cu biblioteca \texttt{System.IO.Pipelines}\cite{system_io_pipelines}
din C\# a relevat mai multe avantaje în utilizarea unei astfel de abordări:
\begin{itemize}
  \item
  Implementarea corectă core să țină cont de toate cazurile-limită
  este facilitată de gestionarea complexității de către
  bibliotecă, cum ar fi alocarea și ștergerea buferelor,
  sau înfășurarea datelor pe mai multe segmente consecutive.

  \item
  Flexibilitatea codului crește, permițând implementarea unui automat finit
  și o rerulare din stări salvate anterior.

  \item
  Eficiența crescută prin soluționarea cazurilor de copiere a datelor în bufere temporare
  de o mărime neoptimă pentru cititor.

  \item
  Centralizarea logicii de citire într-un ciclu unificat,
  reducând duplicarea codului.

  \item
  Separarea completă a modulelor de citire și scriere,
  permițând procesarea datelor în fire separate,
  ceea ce elimină timpul pierdut la \ac{I/O} în timpul procesării.
\end{itemize}

Un prototip al unei biblioteci similare în Zig a fost dezvoltat,
omitând însă separarea modulelor de citire și scriere pentru a reduce complexitatea.
Această parte poate fi adăugată ulterior, nefiind esențială pentru un \ac{MVP}.

\section{Ideea aplicației la nivel înalt}

Având la bază o abordare explorativă, s-a decis programarea aplicației
pornind de la o imagine vagă a rezultatului dorit,
însă cu o direcție clară în ceea ce privește obiectivul general.

Având în vedere faptul că scopul principal al aplicației
este de a facilita explorarea structurii fișierelor \ac{PNG},
s-ar dori ca funcționalitatea să fie direct
influențată și determinată de această structură.
Designul interfeței grafice este conceput pentru a reflecta
caracteristicile specifice ale fișierelor \ac{PNG}.

Fișierele \ac{PNG} sunt compuse din secvențe denumite chunk-uri,
fiecare având o funcție specifică.
De exemplu, chunk-ul \texttt{IHDR} conține informații vitale despre imagine,
precum lățimea, înălțimea, numărul de biți per pixel ș.a.
Se intenționează ca interfața aplicației să pună
în evidență aceste chunk-uri, oferind detalii despre ele utilizatorilor
și permițând modificarea valorilor într-un mod
care nu afectează integritatea fișierului.
Informațiile ar fi prezentate per chunk, atunci când utilizatorul îl alege,
iar fiecare chunk trebuie să fie evidențiat, pentru a-l putea alege și vizualiza.

Pentru a sublinia aspectul de explorare a \textit{formatului} \ac{PNG},
și nu doar manipularea imaginilor în acest format,
se va include în aplicație un editor hexazecimal.
Acesta va prezenta valorile fiecărui octet și
va oferi reprezentări vizuale pentru a facilita distingerea diferitelor chunk-uri.

La selectarea unui chunk, vor fi afișate informații detaliate despre acesta,
incluzând numele, descrierea și lungimea.
Este crucial ca fiecare chunk să fie prezentat cu o structură specifică,
pentru a oferi o înțelegere completă a compoziției și funcționalității fișierelor \ac{PNG}.


\section{Imaginea inițială a implementării la nivel înalt}

În dezvoltarea software, este adesea practic să se abordeze problemele pe măsură ce apar.
Însă procesul de gândire și modul în care se ajunge la soluții
pot adăuga valoare dacă sunt împărtășite.
Deși nu există garanția că ideile înregistrate vor duce
la o soluție optimă sau chiar una funcțională,
și anumite probleme de implementare sunt ignorate la această etapă inițială,
această abordare reflectă natura evolutivă a dezvoltării software.

Excesul de planificare și gândire înainte de începerea scrierii codului
poate adesea conduce la un design incorect sau inferior.
Acest lucru se datorează faptului că în timpul programării pot apărea probleme neanticipate,
din cauza lipsei unei viziuni complete asupra întregului sistem.
Din acest motiv, planificarea detaliată a întregului sistem înainte de începerea dezvoltării
nu este întotdeauna cea mai înțeleaptă abordare.
Cu toate acestea, planificarea la nivel înalt a structurii aplicației,
ținând cont de cerințe și pe baza experienței,
este utilă pentru a descompune problema în subprobleme gestionabile
și pentru a începe implementarea unei soluții.

Pentru a reflecta această viziune, s-a stabilit ca aplicația
să fie împărțită în mai multe module esențiale:
\begin{itemize}
  \item 
  \textbf{Modulul de acces la fișiere după poziții absolute},
  care va gestiona cache-ul segmentelor vizualizate în prezent,
  ștergerea segmentelor nedorite din memorie și citirea datelor din fișier la necesitate.
  Acest modul este o abstracție cheie pentru a simplifica interacțiunea cu fișierele \ac{PNG}.

  \item
  \textbf{Arborele sintactic al fișierului \ac{PNG}},
  care ar trebui să păstreze în memorie doar informațiile despre
  chunk-urile vizualizate la un moment dat.
  Acesta ar permite accesul la informații structurate despre fișier
  și ar fi interfațat cu modulul de interacțiune cu utilizatorul
  pentru a indica ce segmente din fișier sunt vizualizate.

  \item
  \textbf{Parser-ul}, responsabil pentru transformarea datelor
  din fișier într-un arbore sintactic la cerere.
  Acest modul poate consta dintr-un set de funcții specifice pentru această transformare.

  \item
  \textbf{Modulul de interfață cu utilizatorul},
  care va folosi arborele sintactic al fișierului pentru
  a prezenta utilizatorului informații într-o formă atractivă și interactivă.
  Modulul va avea control asupra segmentelor din fișier care sunt vizualizate,
  permitând utilizatorului să actualizeze aceste segmente
  în funcție de chunk-urile afișate în interfață.
\end{itemize}

Așa cum s-a discutat, acest design inițial este un punct de plecare,
iar implicațiile utilizării acestuia urmează să fie analizate pe parcursul dezvoltării.


\section{Oportunitatea de abstracție a parser-ului}

Pe parcursul dezvoltării a parser-ului, indeosebi a funcțiilor de parsare a datelor din chunk-uri,
s-a observat o oportunitate de abstractizare a acestui cod.
Deoarece structura parser-ului este proiectată ca o mașină de stări,
are sens să fie realizată o abstracție pentru a putea construi mașina acesta de stări mai ușor
fără a repeta logica.

Inițial, parser-ul se află într-o stare destinată validării a semnăturii fișierului \ac{PNG}.
Semnătura este o secvență specială de caractere care 
trebuie necesar să apare la începutul oricărui fișier \ac{PNG}.
După citire a semnăturii, parser-ul trece la starea de citire a chunk-ului.
Parsesul trebuie să mai noteze dacă a început să citească următorul chunk.
Acesta este important pentru a indica faptul că dacă fluxul de intrare
se termină după ce s-a început citirea, atunci fișierul nu este complet și 
o eroare trebuie să fie semnalizată.

În timpul citirii a chunk-ului, parserul poate să se afle 
într-o stare specifică destinată fiecărui câmp al chunk-ului:
lungimea, tipul, datele, și suma de control.
Aceste stări sunt urmate unul de altul, adică valorile numerice
ale acestora pot fi derivate din valoarea trecută, de exemplu 
$ S_{date} = S_{lungime} + 1. $
Aceasta poate fi implementată în mod cel mai simplu can un \texttt{enum}
în orice limbaj de programare care le suportă, inclusiv Zig.

Un lucru asemănător se întâmplă la parsarea datelor unui chunk care are un format fix.
De exemplu, chunk-ul \texttt{IHDR} are un set de câmpuri fix, care sunt amplasate unul după altul.

În acestă logică însă se adaugă și ideea de validare mai meticuloasă a valorilor,
de exemplu, dimensiunile nu pot fi zero, iar \texttt{BitDepth} poate lua numai un set specific de valori
și acesta depinde de valoarea lui \texttt{ColorType}.

Încă un element este faptul că valorile ale lor, de exemplu, lungimea, tipul chunk-ului,
lățimea și înălțimea, precum și alte valorile parsate se dorește a fi păstrate undeva,
ca câmpuri ale unei structuri ce descrie nodul respectiv.
În structura finală a aplicației, aceste valori au fost amplasate în noduri ale unui arbore sintactic.

Deci, logica de parsare a unui câmp de obicei are următoarea formă:
\begin{enumerate}
\item
    Se citește numărul necesar de octeți din fluxul de intrare
        și se convertează aceștia în tipul de date dorit (de exemplu, un \texttt{int}).
\item
    Se realizează validarea acestei valori.
    De exemplu, nu se admit valorile dimensiunilor egale cu zero.
    În unele cazuri eroarea nu este groaznică, poate fi înresitrată, iar parsarea poate fi continuată.
\item
    Salvarea valorii într-un câmp pe o structură (sau într-un nod, în structura finală a aplicației).
\item
    Trecerea la următoarea stare.
\end{enumerate}

În plus, pentru debugging ar fi utilă o funcție care afișează drumul de stări curent,
adică, de exemplu, dacă parserul se află în starea parsării a unui chunk \texttt{IHDR}, 
și se află la etapa parsării câmpului \texttt{ColorType},
care este indicat printr-o altă variabilă de stare,
s-ar dori să se afișeze \texttt{Chunk(IHDR) ColorType}, sau ceva asemănător.

Ideea este ca acest proces s-ar putea fi abstractizat în loc de a fi duplicat:
\begin{enumerate}
\item
    În loc de mai multe variabile care să indice starea, aceasta poate fi păstrată ca
    o listă de numeri întregi, indicând un fel de drum pentru următoarea acțiune a parser-ului.
    Clar că drumul acesta ar fi deja generic și și-ar pierde informațiile despre tipul
    \texttt{enum}-ului care indică starea, ceea ce ar fi dezavantajos pentru debugging.
\item
    Logica de afișare a stării poate fi implementată destul de ușor, dacă există o listă de
    șiruri de caractere pentru fiecare index din drumul stării,
    și pentru fiecare valoare posibilă a stării la acel index,
    însă s-ar trebui atunci și să se modifice starea
    de pe poziție 0 de la \texttt{Chunk} la \texttt{IHDR}.
\item
    Ceea ce trebuie de făcut la diferite stări,
    și câtă memorie va fi necesară pentru a păstra nodul poate fi configurat separat,
    într-un mod mai declarativ.
\item
    Stările care se așteapă că vor seta anumite câmpuri
    pot indica ofsetul câmpului pentru ca sistemul să scrie valoarea acolo automat.
    Aceasta poate fi simplificat prin folosirea tehnicilor de metaprogramare oferite de Zig.
\item
    Fiecare stare ar trebui să declare o funcție de inițializare a nodului,
    o funcție de parsare și o funcție de validare a valorii.
    Aici s-ar putea oferi niște funcții de configurare pentru a partaja logica.
\end{enumerate}

Însă, realizarea acestui gând în starea inițială a dezvoltării n-ar fi înțeleaptă,
deoarece această oportunitate s-a observat la momentul
realizării a primului tip de chunk, \texttt{IHDR},
deci este posibil că nu s-ar generaliza bine pentru toate tipurile de chunk-uri.
Încă, s-a menționat deja anterior că această abordare reduce capacitatea de debugging.

În structura finală a aplicației s-a observat că chunk-urile au o structură destul de diferită unul de altul.
Cu toate că abordarea aceasta s-ar putea fi aplicată la unele chunk-uri,
integrarea acestui subsistem cu logica obișnuită procedurală a celorlalte chunk-uri
ar fi complicată și ar reduce semnificativ meritul acestei abordări. 

\section{Zlib și Deflate}

Formatul \ac{PNG} folosește comprimarea datelor prin algoritmul Zlib.
Comprimarea se folosește pentru chunk-urile \texttt{zTXt} (text comprimat),
\texttt{iCCP} (profil \ac{ICC}), \texttt{IDAT} (datele pixelilor), precum și altele.
Pentru a înțelege problema mai bine, ar fi benefic să se înțeleagă cum funcționează algoritmul Zlib.
În plus, deoarece algorimul este parte din standardul \ac{PNG},
și structura acestuia poate fi decodificată și analizată,
ar fi benefic să se realizeze un fel de parser special pentru Zlib pentru a putea vizualiza nodurile Zlib
în mod bogat în interfață.
Din această cauză, s-a decis să se realizeze implementarea unui decoder Zlib de la zero.

Structura parserului menționată până acum poate fi aplicată și pentru formatul Zlib.
Singura diferență este că formatul Zlib este bazat pe biți, dar nu pe octeți.
Însă deoarece poziția pe biți absolut nu ține de gestionarea buferilor,
componenta \texttt{pipelines} care realizează fluxul de date nu va trebui să fie modificată.
Starea parserului Zlib poate să țină cont de poziția pe biți ca o variabilă privată, deoarece
acest concept nu se revarsă la procesarea \ac{PNG}.
Însă, poziția pe biți ar trebuie să fie utilă pentru vizualizare a formatului.

În structura finală a aplicației, poziția pe biți a componentelor din fluxul de date a fost sălvată la crearea nodurilor.

Mai complicat conceptual este sistemul de decomprimare,
deoarece acesta trebuie să păstreze octeții decodificate pentru a putea referi la acestea
în procesul de decomprimare, până la 32 KB de date.

A fost realizată o abordare simplă --- se păstrează toți octeții într-un bufer dinamic.
S-ar putea aplica o abordare mai complexă, însă acest element al programului
nu este atât de important sau interesant din punct de vedere a formatului pentru a merita optimizarea.

\subsection{Testarea}

Problema legată de testare este faptul că, deoarece programul este orientat
la decomprimare și nici nu realizează un compresor,
este dificit să se genereze niște date pentru teste.

Sunt două variante care ar putea fi folosie:
\begin{enumerate}
    \item
        Se poate folosi un compresor existent, adică o altă librarie, pentru a genera datele.
        Minusul acestei abordări este faptul că codul de generare a datelor atunci va exista
        ca un modul independent și nu poate fi ușor folosită abordarea "kitchen sink", adică
        compresia dintr-o structură de date, și urmând-o decompresia, după ce să se verifice
        dacă rezultatul este echivalent cu structura de date originală.
        Însă, testarea de așa fel n-ar fi de neatins --- cu o anumită masură de lucru,
        poate fi realizat un sistem care permite testele declarative folosind așa abordare.
        Pentru prototipul dat însă s-a decis că această abordare ar fi prea consumătoare de timp.
    \item
        Se poate găsi niște date de test, și a le folosi pentru a face testarea
        la întregul sistem, cu diferite intrări, fără a înțelege toate nuanțele ale datelor de intrare.
        Adică, dacă se găsește o eroare pentru un samplu corect -- testul se eșuează,
        și invers, pentru un samplu incorect decompresia trebuie să se eșueze.
        Una din referințe \cite{gzip_impl} folosește așa abordare pentru teste negative,
        însă are datele pentru formatul gzip, dar nu zlib, din care cauză acestea nu au putut fi folosite.
\end{enumerate}

De fapt există și încă o abordare -- să nu facă testarea la modulul zlib direct.
Pentru prototip, această abordare este cea mai aplicabilă pentru a putea sălva timpul.

Testarea indirectă oricum va fi folosită la testarea intrărilor diferite ale formatului \ac{PNG},
deoarece acesta numaidecât folosește Zlib pentru chunk-urile \texttt{IDAT} care trebuie să fie prezente
în orice exemplu de fișier \ac{PNG}.

În plus, decodificarea deja este verificată conform câmpului de suma de control Adler32,
care în cazul dacă corespunde valorii acestei sume de control calculate pe baza biților decodificați,
indică probabilitatea înaltă că fișierul a fost decodificat corect. 
Notez că probabilitatea este înaltă, dar nu categorică din cazul că aceasta este într-un fel o funcție hash
care nu dau garanții exacte față de integritate, ci doar o certitudine înaltă.


\section{Procesarea erorilor}

La implementarea inițială a prototipului s-a observat că erorile pot fi semnalizate
la momente diferite de detectare a lor și unele din ele pot avea niște date asociate
care trebuie să fie accesibile de utilizator, de dorit într-un mod consistent.

De exemplu, când se citește un număr întreg de 4 octeți din fluxul de intrare,
avem 3 posibilități diferite de implementare a acestei idei.
Acestea implică transferul diferit al contextului de eroare și
urmează în poziții diferite înregistrate ale secvenței curente de intrare.

\begin{minted}{zig}
pub fn impl(context: *Context) !void
{
    // ...

    switch (context.state.action)
    {
        // ...

        .Number =>
        {
            // Citirea unui întreg, modificarea fluxului.
            const number = try pipelines.readInt(context.sequence());

            // Salvarea valorii pe context.
            context.state.number = number;

            // Validarea.
            if (number == 256)
            {
                return error.CannotBe256;
            }
        },

        // ...
    }
}

pub fn callSite()
{
    // ...

    impl(&context)
    catch |err|
    {
        switch (err)
        {
            error.CannotBe256 =>
            {
                // Dacă mai multe stări pot produce această eroare,
                // Trebuie să se verifice în care stare se află parserul.
                switch (context.state.action)
                {
                    // ...

                    .Number =>
                    {
                        std.debug.print("The number {} is invalid while parsing Number\n", .{
                            context.state.number
                        });
                    },

                    // ...
                }

                return error.ParsingFailed;
            },
        }
    };
}
\end{minted}

O altă variantă ar fi putea următoarea, unde octeții citiți
se consumă numai dacă nu s-a observat o eroare.

\begin{minted}{zig}
pub fn impl(context: *Context) !void {
    // ...
    switch (context.state.action) {
        // ...
        .Number => {
            // Citirea unui număr din fluxul de date, fără a consuma octeții.
            const number = try pipelines.peekInt(context.sequence());

            // Salvează contextul.
            context.state.number = number.value;

            // Validarea.
            if (number.value == 256) {
                return error.CannotBe256;
            }

            // Se consumă octeții.
            number.apply(context);
        },
        // ...
    }
}
\end{minted}

Se mai poate transmite eroarea într-un mod diferit.
Următoarea abordare permite înregistrarea mai multor erori.
Pentru moment, așa ceva nu se folosește, însă tot este o abordare validă.

\begin{minted}{zig}
pub fn impl(context: *Context) !void {
    // ...
    switch (context.state.action) {
        // ...
        .Number => {
            // Citirea unui întreg.
            const number = try pipelines.readInt(context.sequence());

            // Validarea.
            if (number == 256) {
                context.state.addError(.{
                    .err = error.CannotBe256,
                    .context = number,
                });
            }
            else {
                // Se poate folosi sistemul de tipuri pentru a reprezenta
                // faptul că valoarea a fost validată.
                context.state.number = ValidNumber {
                    .value = number,
                };
            }
        },
        // ...
    }
}

pub fn callSite() {
    // ... 
    const errorScope = context.state.errorScope();

    impl(&context) catch |err| {
        // Aici, doar sunt posibile doar erorile legate cu alocarea memoriei
        // și eroarea NotEnoughBytes.
        // ...
    };

    if (errorScope.errorsHappened()) |errors| {
        for (errors) |e| {
            switch (e.err) {
                // ...
                case error.CannotBe256 => {
                    const numberActuallyRead = try coerce(u32, e.context);
                    std.debug.assert(numberActuallyRead == 256);
                },
            }
        }
    }
}
\end{minted}

În varianta finală a aplicației, datele sunt sălvate în noduri înainte de a returna erori.
Din aceasta cauză, ultimul nod care a fost completat mereu conține întregul context al erorii.
Abordarea aceasta este folosită în aplicație, acolo unde este posibil.
Este interesant faptul că își pierde relevanța faptul dacă a fost mișcată secvența sau nu,
deoarece poziția pe octet este salvată în nod, și sistemul oricum nu poate continua procesul de citire,
cunoscând că fluxul următor este incorect
(aceasta ar fi mai relevant în codul sursă pentru un limbaj de programare).

La nivel înalt, procesarea erorilor în așa sistem s-ar asemăna cu următoarea:

\begin{minted}{zig}
pub fn impl(context: *Context) !void {
    // Este creat un nod nou pe stack-ul nodurilor.
    try context.level().pushNode(.{
        .Foo = context.state.action,
    });
    defer context.level().pop();

    switch (context.state.action) {
        // ...
        .Number => {
            const number = try pipelines.readInt(context.sequence());

            try context.level().completeNodeWithValue(.{
                .Number = number,
            });

            if (number > 200) {
                return error.CannotBeMoreThan200;
            }
        },
        // ...
    }
}

pub fn callSite() {
    // ... 
    const errorScope = context.state.errorScope();

    impl(&context) catch |err| {
        switch (err) {
            // ...
            .CannotBeMoreThan200 => {
                const lastNodeData = context.getLastCompletedNodeData();
                print("Number {} cannot be more than 200\n", .{ lastNodeData.Number });
            },
        }
    };
}
\end{minted}

Însă s-a hotărât că procesarea explicită a acestora de program nu merită atenția,
deci eroarea este pur și simplu afișată la ecran, terminând parsarea,
dar totodată afișând și interfața obișnuită.
Uitându-se la interfață, utilizatorul poate deduce ce a căuzat eroarea,
deoarece arborele s-ar termina pe acea poziție.

\section{Complicațiile asociate cu citirea chunk-ului \texttt{IDAT}}

\subsection{Descrierea problemei de ``sărituri''}

Posibilitatea de a putea păstra informațiile despre originea fiecărui "nod",
adică poziția a acestuia absolută din fișier,
precum și posibilitatea de a trata fluxul de date ca unul linear nu sunt direct compatibile
atunci când fluxul de date poate "sări", adică atunci când pozițiile absolute
între diferitele segmente nu sunt consecutive.
Deoarece unul singur nod poate să se afle la marginea a două segmente (potențial mai mult ca două),
ideea că locația fiecărui nod poate fi descrisă de locația lui absolută în fișier și
lungimea lui deja nu se va aplica.

Cu toate că pentru noduri regulare din formatul \ac{PNG} așa ceva nu este posibil,
chunk-ul \texttt{IDAT} este special în acest sens.
Toate chunk-urile acestea conțin unul singur stream Zlib partajat,
iar parserul \ac{PNG} se consideră incorect dacă nu realizează corect
orice distribuție a fluxului Zlib între chunk-uri.
Adică parserul \ac{PNG} nu poate presupune de exemplu că blocul Zlib va termina de fiecare dată
împreună cu chunk-ul \texttt{IDAT} în care se află.
De fapt, este posibilă situația că biții ultimului octet au rămas necitite până la capăt
în primul chunk \texttt{IDAT}, continuându-se în următorul chunk.

Deoarece arborele Huffman din specificația Zlib permit lungimea maximă de 16 biți pentru coduri,
iar programul trebuie să considere aceste coduri ca noduri separate,
și acestea pot să se afle la ofset-uri de biți nealiniate cu granițele octeților,
în cel mai rău caz se poate întâmpla ca unul singur nod să se afle în 3 chunk-uri în același timp.
De exemplu, primul bit poate să se afle la sfârșitul primului chunk,
următoarele 8 biți pot să se afle în întregul următorul chunk, dacă acesta are lungimea 1, ce este posibil,
și atunci se va termina la începutul celui de-al treilea chunk.

\subsection{Soluționarea problemei}

Pentru a păstra capacitatea de a putea procesa datele folosind secvențele,
de părca acestea erau consecutive, ar trebui să includă acele părți trecute necitite până la capăt
la începutul secvenței, când se realizează procesarea fluxului Zlib.

Prima problema era că secvența trebuia să includă doar segmentele din manager de bufer principal,
folosind de către cititor.
De fapt, segmentele erau păstrate ca index-urile în tabloul de segmente, cu un ofset de bază.
Ca să devină posibil de inclus niște segmente dinafara buferilor principali la începutul secvenței,
modul acesta de adresare a fost schimbat la o listă înlănțuită alcătuit din pointeri.
Astfel, este posibil să seteze segmentul adăugator ca primul segment din secvență, urmându-l cu
primul segment din secvența inițială, pentru a crea secvența nouă.

Următoarea problema era că implementarea inițială a secvențelor din modulul \texttt{pipelines} presupunea
că toate segmentele care se află între primul și ultimul segment se includ în secvența în întregime.
Însă, secvența poate avea ca prima poziție segmentul inițial \textit{la un ofset}.
Deoarece el este predestinat să devină al doilea segment după adăugare a primului segment adăugător,
s-a hotărât să-i miște buferul de început, aplicând ofsetul.

Această soluție nu se simte curată.
Sunt alte abordări puțin mai complicate, dar care potențial vor face implementarea arborelui mai ușoară.
Deoarece acele segmente de început la moment sunt temporare,
nodurile din arbore nu pot să se refere la acestea, iar pozițiile din acestea pot să nu existe în buferi la momentul curent.

Poate o abordare mai bună ar fi ca acele segmente veche să se păstreze în lista buferilor,
pentru a putea să se adreseze la acestea în secvențe,
și ca segmentele din secvențe să-și poată specifica ofseturi,
cu însele date păstrate separat, doar în buferi principali.
Atunci ar trebui să se adauge și un fel de "comsumed position hint" la cititorul,
ca el să păstreze segmentele care încă nu s-au citit până la capăt.

De fapt, așa idee se folosește și în biblioteca \texttt{System.IO.Pipelines} din C\#,
însă la implementarea inițială nu era clar de ce ar fi necesară această abordare.
După ce s-a întâlnit problema care se rezolvă folosind această idee, s-a clarificat și sensul ei.

Problema aceasta s-a rezolvat prin introducerea distincției între nodurile sintactice,
care reprezintă bucățile concrete din fișier, și ale datelor fiecărui nod.
Datele nu au o locație și pot fi partajate prin mai multe noduri.

În plus, a fost realizată o legătură între nodurile care sunt într-un fel o singură parte a aceluiași obiect,
printr-o listă semantică dublu înlănțuită, creată între noduri.
Deci, dacă se întâmplă ca unul și același nod se continuă în următorul chunk,
acesta numaidecât va avea și o referință la nodul care îl continuă,
iar acel nod va avea o legătură înapoi la primul nod.
Aceasta poate fi util pentru a arăta utilizatorului de exemplu poziția nodului de continuare.

Interesant este și faptul că această structură poate fi expresată în mod general,
nu doar pentru nodurile din acest chunk.
Datorită acestui fapt implementarea funcționalităților legate cu această proprietate
nu trebuie să țină cont de tipul de nod.


\section{Dezvoltarea în \ac{WSL}}

Dezvoltarea pe Linux este eclipsează dezvoltarea pe Windows -- aceasta este un fapt incontestabil.
\begin{itemize}
    \item 
        Windows nu are un manager de pachete integrat în sistem.
        Cu toate că pe versiuni noi există aplicația WinGet, 
        aceasta nu este atât de stabilă și dezvoltată ca apt-get de pe Ubuntu.
        Există și Chocolatey, însă acesta nu permite instalarea pachetelor de ultimă versiune,
        dacă această versiune nu este în lista lor a ``pachetelor de încredere'',
        și nu include toate capacitățile în versiunea gratuită.
        (Aceste afirmații sunt fără referințe bibliografice deoarece 
        au fost aflate în trecut și sursele care le confirmă au fost pierdute.)

    \item
        Este practic imposibil să facă un build la orice aplicație în mod fiabil.
        Windows este foarte sensibil la configurări globale ale sistemului,
        mereu lipsește careva pachete instalate, sau tocmai nu suportă unele pachete, etc.
        Compilarea aplicațiilor pe Windows mereu implică ``probleme pe cap''.
        Pe de altă parte, pe Linux aceasta este trivial.
        După instalarea pachetelor necesare, build-urile lucrează ideal în aproape 100\% din cazuri.

    \item
        Unele aplicații nu sunt pe Windows.
        Ca de exemplu \texttt{Valgrind} și \texttt{MSan}.

    \item
        Unele aplicații așteaptă sistemul de tip Unix.
        De exemplu, abordarea răspândite pentru dezvoltarea plugin-urilor
        pentru Neovim este să se presupună că sistemul este Unix,
        deoarece dezvoltatorul oricum trebuie să folosescă Unix pentru a fi productiv.
\end{itemize}

Din fericire, Windows a introdus capacitatea minunată \ac{WSL}.
Fără a intra în mecanisme funcționării acesteia, deoarece aceasta nu este în scopul lucrării,
pe scurt \ac{WSL} poate fi explicat ca un sistem de Linux integrat în Windows, care poate citi fișierele din Windows.

Destul de recent a fost introdusă și capacitatea de a rula aplicații grafice prin \ac{WSL}.
Ferestrele create în așa mod pot fi manipulate ca orice altă fereastră pe Windows.

Mulțumită WSL, toata dezvoltarea a fost realizată practic pe Linux, 
ce a simplificat lucrul cu librării externe, și instalarea instrumentelor adăugătoare, nemenționate explicit în text.

\section{Construirea arborelui sintactic}

Folosirea unui arbore sintactic este o abordare bună pentru problemele 
unde datele sunt structurate în mod ierarhic și se cere a fi analizate sau într-un fel accesate pe urmă.
Proprietatea cheie a acestei abordări este faptul că arborele poate fi \textit{abstract},
ceea ce înseamnă că acesta este o reprezentare la un nivel mai înalt a informațiilor despre datele
din care a fost construit.
Din această proprietate origină avantajul principal al acestei abordări --
construirea arborelui analizând datele neprocesate și folosirea arborelui
pentru analiză pot fi implementate separat, comunicând prin acest arbore.
Aceasta simplifică realizarea sistemului, impărțindu-l la două module majore cu responsabilitățile respective,
care pot fi implementate în izolare, conform interfeței arborelui.

Folosirea unui arbore este cea mai evidentă abordare pentru sistemul în cauză.
Această abordare divizează sistemul la bucata care construiește arborele
(partea de citire a fișierului, parser-ul, și codul care crează și gestionează alocarea nodurilor),
și bucata care analizează arborele derivat (interfața grafică în cazul dat).
Aceste bucăți pot fi realizate separat, ceea ce simplifică procesul de dezvoltare.

\subsection{Problemele abordării inițiale}

În implementarea inițială a sistemului, arhitectura a fost concepută în așa fel ca
logica de creare a arborelui să fie cu totul independentă de logica citirii datelor din fluxul de date.
S-a conceput ca transmiterea informațiilor despre nodul curent să fie la nivelul stării generale a citirii.
Deci, citirea următorului element din flux de date ar presupune scrierea informațiilor interpretate
într-un câmp prestabilit, în obiectul care reprezintă datele elementul
din fișier care se citește la momentul dat (fie chunk-ul curent), păstrat în starea generală de citire.
După aceasta, codul care construiește arborele sintactic ar detecta care tip de nod a fost citit la cea mai recentă etapă 
(este o altă problemă, descrisă separat mai târziu),
și, în dependența de stare în care se afla parserul înainte de cea mai recentă operație de citire,
ar trebui să acceseze exact același câmp în care au fost copiate datele.

Această abordare are mai multe probleme:
\begin{enumerate}
    \item
        Câmpul în care au fost scrise informațiile trebuie să fie sincronizat
        între codul de scriere și codul de citire.
    \item
        Determinarea din care anume câmp trebuie să fie citite datele
        depinde de starea parserului înainte de ultima operație,
        dar nu doar de tipul nodului produs.
        De exemplu, nodurile generate din elementele formatului Zlib pot apărea
        la mai multe chunk-uri \ac{PNG}, dar ar avea același tip de nod.
    \item
        Parserul poate produce doar un singur tip de nod la fiecare operație, deci trebuie
        să fie oprit după fiecare operație de scriere a datelor într-un câmp.
        Mai mult ca aceasta, parserul nu poate să treacă la următoarea stare imediat,
        deoarece aceasta ar putea elimina unele informații necesare pentru a crea următorul nod.
\end{enumerate}

Următoarea problemă este problema detectării tipului curent de nod.
Deoarece arhitectura sistemului s-a conceput în așa fel ca parserul să nu cunoască despre tipuri de noduri,
nu putem transmite aceste informații direct din parser la codul care folosește parserul pentru
a construi arborele sintactic.
Deci, aceste informații trebuie să fie derivate în mod dinamic pe partea
care intepretează informația primită de la parser.
Pentru acest lucru, trebuie să fie posibil de detectat pentru ce stare au fost citite informații
la ultima invocare, sau cel puțin să fie creat nodul înainte de a realiza invocarea.
După invocare, trebuie să se stabilească care noduri pot fi umplute cu informații,
și dacă trebuie să se creeze noduri noi.
Sistemul de gestionare a acestei informații devine destul de complicat,
și necesită ca codul care construiește arborele să cunoască despre semnificațiile stărilor parserului,
deci are loc și duplicarea structurii stărilor.

Următoarea problemă constă în ceea că faptul de creare
și completarea nodurilor la diferite niveluri trebuie să fie înregistrata la nivel de parser.
Într-un fel, la sfârșit parser-ul trebuie să îndeplinească operațiunile
de bază necesare pentru a crea arborele, fără a folosi abstracția arborelui.

Aceste probleme nu semnifică că abordarea nu poate fi folosită în practică,
dar provoacă o imperativă de a căuta o soluție alternativă.
Prima idee destul de evidentă este de schimbat puțin arhitectura,
permițând parserului să cunoască unele concepte care țin de noduri sintactice,
dar totuși să lase responsabilitatea de a aranja nodurile în memorie unui modul extern.

Deci, ideea este ca parserul să genereze un flux de noduri,
care să conțină informațiile interpretate,
pe lângă intervalului citit din fișier pentru a genera aceste informații,
și a adâncimii, pentru a putea determina la care nod părinte acesta trebuie să fie atașat.

\subsection{Proiectarea abordării noi}

În urmă analizei situației a devenit mai clară structura favorabilă de sistem:
\begin{itemize}
    \item 
        Structura interfeței grafice rămâne neschimbată, 
        deoarece aceasta nu este implicată în crearea arborelui.

    \item
        Modulul de gestionare a arborelui va fi separat de logica creării al arborelui.
        De fapt, așa era și înainte, însă acum această parte de logică va fi mișcată mai aproape de parser.
        
    \item
        Parserul acum va cunoaște despre existența nodurilor, însă nu va interacționa cu ele direct.
        Adăugarea logicii de gestionare a stivei de noduri și crearea nodurilor în parser s-a părut încurcătoare,
        din aceasta cauză s-a hotărât să fie creat încă un modul pentru această funcționalitatea.
        Parserul va folosi acest modul, în loc de a interacționa cu stiva și cu nodurile direct.

    \item
        Acest modul va avea responsabilitatea de a crea nodurile atunci când crește adâncimea stivei în parser,
        semnalizat de parser, și va comunica cu modulul de gestionare a nodurilor din arbore.
        Interfața acestui modul reprezintă operațiunile cu nodul de pe un nivel concret de pe stivă, 
        așadar a fost numită \texttt{LevelContext}.

    \item
        Interfața care permite interacționarea între \texttt{LevelContext}
        și modulul care gestionează arborele a primit numele \texttt{NodeOperations}.
        Acesta definește funcțiile de bază de creare și finalizare a nodurilor.
\end{itemize}

\texttt{NodeOperations} nu trebuie să fie numaidecât abstractizat în această cauză,
adică nu numaidecât trebuie să fie folosit polimorfismul dinamic.
Modulul \texttt{LevelContext} ar putea să se interfațeze direct cu modulul de gestionare a arborelui,
folosind direct abstracțiile lui de noduri, identificare a nodurilor,
modul de implementare a structurii părinte-fiu, etc.

În loc de aceasta, s-a hotărât să introducă încă un nivel de abstracție pentru a evidenția această separare.
A fost definit un set de abstracții pentru identificatori de nod,
folosit ca niște valori opace pentru a adresa la noduri de către \texttt{LevelContext}.
În mod similar, a fost creat un tabel virtual și o implementare a acestuia pe partea modulului de gestionare a arborelui.

\section{Modulul de gestionare a arborelui sintactic}

În continuare, pentru a simplifica explicațiile, modulul dat va fi adresat după numele \textbf{arbore}.
În esența, arborele permite crearea nodurilor și accesarea lor în viitor.

\subsection{Structura nodurilor}

Fiecare nod se află pe o poziție concretă din fișier și poate avea noduri fii.

Fiecare nod are un tip asociat care indică cărei componente din fișier acesta corespunde.
De exemplu, un nod poate avea tipul \texttt{Datele din chunk = Antet},
indicând că nodul corespunde la elementul din fișier cu chunk-ul de antet,
și deoarece conține niște noduri fii, acesta nu este nodul terminal.
Dintre nodurile fii ale acestui nod se va afla nodul cu tipul \texttt{Antet = Lățimea}
care va fi asociat datele \texttt{Number = 32}.

S-a hotărât că în loc de pointeri la noduri va fi folosit un index în tablou cu nodurile.
În cazul dat, aceasta doar face faptul că nodurile sunt păstrate într-un singur tablou mai evident,
și permite schimbarea mărimii acestui tablou.
În plus, aceasta permite ca nodurile să fie adresate într-un mod stabil de către \texttt{LevelContext},
în sensul că acesta poate păstra indicii ca identificatorii fără a-și face griji că nodurile pot fi mișcate în memorie.
Există și alte avantaje ale acestei abordări care cu toate că nu necesar se aplică pentru aplicație în cauză,
fac folosirea indicilor în loc de pointeri ca soluția implicită în mai multe cazuri.

La dezvoltarea sistemului s-a considerat dacă păstrarea nodurilor după niveluri ar fi preferată
peste păstrarea lor liniar într-un singur bloc de memorie.
Ideea este că această proprietate ar putea fi folosită pentru a accelera procesul de căutare
a drumului de noduri după poziția din fișier.
Separarea nodurilor într-un alt mod mai conștient ar putea simplifica
și operațiile de ștergere a nodurilor trecute.
Dacă nodurile ar fi păstrate după mai multe tablouri,
aceasta poate fi indicat printr-un segment de biți dintr-un identificator compus.
Însă faptul este că operațiile de căutare sunt foarte rapide,
chiar dacă sunt realizate folosind căutarea cea mai simplă liniară după fii,
iar ștergerea nodurilor care au trecut peste zona de vizibilitate
n-a fost implementată deoarece n-a fost considerată importantă pentru funcționarea aplicației.

\subsection{Datele nodurilor}.

În mod asemănător, datele din noduri sunt păstrate după un index într-un tablou separat.
Deoarece datele sunt reprezentate printr-o uniune etichetată (tagged union),
ar fi prea risipitor ca acestea să fie păstrate într-un singur tablou.

Problema este că fiecare instanță de o uniune etichetată are
mărimea etichetei plus mărimea celui mai mare tip,
chiar dacă tipul valorii păstrate în această valoare ocupă mai puțin spațiu.
De exemplu, dacă este păstrat o valoare pe un octet,
iar uniunea etichetată admite ca cel mai mare tip un \texttt{RGB16} pe 48 de biți,
spațiul ocupat va fi mărimea etichetei (de exemplu, 8 biți) adăugată la mărimea acestui tip,
deci 56 de biți (ignorând padding-ul).
Prin urmare, este risipit foarte mult spațiu, dacă valorile sunt păstrate într-un singur tablou.

O abordare mai eficientă este de a păstra fiecare tip de valoare într-un tablou,
indicând în identificatorul cărui tablou corespunde datele după acel identificator.
Atunci valorile de fiecare mărime posibilă pot fi păstrate într-un tablou propriu,
ocupând doar acel număr de biți per fiecare valoare, 
iar valoarea etichetată s-ar putea fi recreată la solicitare.
Această abordare și a fost realizată în aplicație\ref{appendix:main__TaggedArrayList}

S-ar mai putea folosi abordarea de a elimina eticheta din date,
deducând tipul corect al etichetei din tipul nodului,
însă s-a dorit ca aceste concepte totuși să fie mai independente pentru
a simplifica adresarea la date și pentru a avea flexibilitatea de
a putea păstra mai multe tipuri de date pentru același tip de nod.

Unica constrângere care va fi adăugată dacă este folosită această abordare este că
tipul inițial atribuit unui nod cu date nu poate fi schimbat pe urmă.
Aceasta implică și faptul că dacă se dorește ca datele să fie păstrate în aceeași ordine ca și
nodurile cu care acestea sunt asociate, ele trebuie să fie create împreună cu crearea nodului în cauză.
Însă deoarece nodurile nu vor fi șterse în această aplicație,
iar tipul de noduri nu trebuie să fie schimbat, aceasta nu este groaznic.


\section{Implementarea Zlib}

\subsection{Introducere}

Zlib este formatul de comprimare folosit în scopul unelor chunk-uri din formatul \ac{PNG}.
De exemplu, chunk-ul \texttt{zTXt} definește câmpul \texttt{Compressed text},
care include direct șirul compresat în formatul Zlib.

Toate datele pixelilor, adică datele chunk-urilor \texttt{IDAT}, sunt comprimate folosind acest algoritm.

Asemănătoare cu formatul \ac{PNG}, Zlib include un câmp folosit pentru verificarea integrității datelor.
Algoritmul folosit pentru calcularea acestui câmp este numit Adler32.
Cheia este că acesta este calculat pe baza datelor \textit{decomprimate},
deci poate fi folosit pentru a verifica și integritatea datelor, și corectitudinea programului implementat.

Zlib are și alte capacități ca suportul pentru dicționare, permite setarea parametrilor de comprimare, etc.
Însă, acestea nu sunt relevante pentru interpretarea unui fișier \ac{PNG}.
Dicționarele absolut nu sunt folosite, și chiar sunt interzise după specificație \cite{png_spec_chapter_deflate}.
Parametrii de comprimare sunt folositori doar pentru procesul de comprimare,
adică, în context-ul formatului \ac{PNG}, generarea unui fișier din datele pixelilor.
Deoarece scopul aplicației este de a realiza \textit{citirea} unui fișier \ac{PNG},
dar nu generarea unui așa fișier, acestea nu vor fi menționate în continuare.
Câmpurile cu aceste date însă sunt citite și validate în mod normal, conform specificației.

\subsection{Subformatul \texttt{Deflate}}

Partea esențială a formatului Zlib este subformatul integrat \texttt{Deflate}.
Deflate definește 3 mecanisme de comprimare: datele \textit{fără comprimare},
și comprimarea folosind arbori Huffman, metoda \textit{fixă} și metoda \textit{dinamică}.

Metoda fixă se implementează mai ușor, deoarece nu necesită constuirea unei structuri de date.
Specificația dă niște tabele, folosind care este interpretat fluxul de biți.

Metoda dinamică este mai complicată și necesită citirea arborelui Huffman
folosit pentru a decomprima fluxului de biți în continuare.
Este dificil de implementat codul corect pentru această metodă tocmai deoarece descrierea
la nivel înalt al algoritmului nu corespunde direct la implementare.
În special, proprietatea codurilor Huffman că oarecare cod nu poate apărea
la începutul unui alt cod poate fi pe deplin apreciată numai atunci
când persoana singură realizează o implementare.

Fluxul de biți este procesat într-o secvență de simboluri,
care reprezintă ori literale, adică singuri octeți decomprimați,
ori referințe de o anumită lungime înapoi la octeții din bufer decomprimat,
după anumită distanță de la poziția curentă.
Aceste simboluri nu apar direct în fluxul de intrare,
dar sunt codificate folosind un arbore Huffman.

\subsection{Arbori Huffman pe scurt}

Merită a fi menționată ideea arborilor Huffman fără a explica întregul algoritm adânc.
Fiecărui simbol este atribuit un cod de o lungime în funcția frecvenței de apariție a acestui simbol
în secvența de ieșire.
Adică simbolurile care apar mai des sunt atribuite coduri mai mici,
iar simboluri care sunt mai rare primesc și coduri pe mai mulți biți.
Deoarece codurile apar unul după altul în fluxul de date codificate,
fără nici un separator, secvența de început al unui cod trebuie să ajungă pentru a determina lungimea codului,
deoarece aceasta este necesară pentru a putea citi numărul corect de biți și a realiza transformarea din cod în simbol.

În caz general, această problemă este rezolvată construind un arbore Huffman general,
însă codurile din algoritm Deflate sunt atriuite într-un mod special, astfel încât ele sunt atribuite consecutiv.
Aceasta permite să simplifică codul care realizează decodificarea.

În abordarea generală, se realizează o traversare a arborelui Huffman,
care ia drumul stâng dacă în secvența apare un zerou, și drept, dacă apare o unitate.
Algoritmul se termină atunci când ajunge la un nod terminal, semnificând că codul s-a potrivit simbolului din acest nod.

\subsection{Specificul implementării arborelui Huffman în metoda dinamică}

Folosind proprietatea alocării consecutive a codurilor,
implementarea arborilor dinamice Huffman în Deflate se simplifică în următorul mod:
\begin{itemize}
    \item 
        Se stabilește un set de sloturi reprezentând lungimi diferite de secvențe.
        Fiecare slot reprezintă faptul că simbolurile din acest slot
        sunt codificate cu numărul de biți egal cu poziția secvențială a slotului, de la unu.
    \item
        Fiecare slot ține simbolurile care corespund codurilor, în mod consecutiv.
        Deci, fiecare din ele ține un tablou de simboluri.
    \item
        Fiecare slot salvează și numărul de coduri cumulativ înaintea tuturor codurilor din sloturi precedente.
        Deci, notând numărul acesta ca \( S_i \), iar numărul de noduri în fiecare slot ca \( N_i \),

        \begin{equation}\label{cod_prop}
            S_0 = 0 \\
            S_i = S_{i - 1} + N_{i - 1}
        \end{equation}
\end{itemize}

Datorită proprietății că fiecare cod este atribuit consecutiv,
de la cea mai scurtă lungime a codului la cea mai lungă,
procesul de decodificare poate fi sumarizat în următoarea secvență de cod:

\begin{minted}{c}
lungime = 1
while (lungime < sloturi.lungime)
{
    cod = citeșteBiți(fluxDeBiți, lungime);
    slot = sloturi[lungime];
    if (cod < slot.s + slot.n)
    {
        mișcăFluxulDeBiți(fluxDeBiți, lungime);

        index = cod - slot.s;
        simbol = slot.simboluri[index];
        return simbol;
    }

    lungime += 1;
}
error("Cod nevalid");
\end{minted}

A se vede codul întreg pe GitHub, sau în anexa \ref{appendix:main__parser_zlib_helper}.

Această idee era cea mai importantă de a-și da seama în procesul de realizare a algoritmului.
Restul algoritmului nu merită atenție, deoarece implementarea nu a avut așa insight-uri.
Merită de menționat doar faptul că arborele este prezentat nu direct,
dar este și acesta codificat folosind o altă codificare Huffman,
însă acelea sunt codificate tot folosind un set de coduri prestabilit
ca la abordarea cu codurile fixe, deci este mai ușor de implementat.

\chapterConclusionSection{implementation_chapter_title}


\unnumberedChapter{Concluziile Finale și Recomandările}


\newpage
\markpage{usefulStuffEnd}


% Bibliography
\bibliographystyle{plain}
\bibliography{bibliography}
\addcontentsline{toc}{chapter}{\bibname}

% Appendices
\appendix

% Number with arabic numbers instead of Roman
\renewcommand{\thechapter}{\arabic{chapter}}
% Prepend Anexa to section names, center them
\titleformat{\section}[block]{\normalfont\normalsize\bfseries\filcenter}{Anexa \thesection~}{0pt}{}

% Every section on new page
% \newcommand{\sectionbreak}{\clearpage}

% Since we've got just a single chapter in the appedices,
% but which is also the name of the Appendix chapter, it should be omitted.
% Makes little sense, but ok I guess.
\setcounter{chapter}{1}

\unnumberedChapter{Anexe}
% insert appendices here

\end{document}
% vim: fdm=syntax


\section{ast.zig}\label{appendix:main__ast}
\inputminted{zig}{../src/ast.zig}

\section{TaggedArrayList.zig}\label{appendix:main__TaggedArrayList}
\inputminted{zig}{../src/TaggedArrayList.zig}

\section{main.zig}\label{appendix:main__main}
\inputminted{zig}{../src/main.zig}

\section{module.zig}\label{appendix:main__parser_module}
\inputminted{zig}{../src/parser/module.zig}

\section{pipelines.zig}\label{appendix:main__parser_pipelines}
\inputminted{zig}{../src/parser/pipelines.zig}

\section{common.zig}\label{appendix:main__parser_png_common}
\inputminted{zig}{../src/parser/png/common.zig}

\section{chunks.zig}\label{appendix:main__parser_png_chunks}
\inputminted{zig}{../src/parser/png/chunks.zig}

\section{parser.zig}\label{appendix:main__parser_png_parser}
\inputminted{zig}{../src/parser/png/parser.zig}

\section{utils.zig}\label{appendix:main__parser_png_utils}
\inputminted{zig}{../src/parser/png/utils.zig}

\section{zlib.zig}\label{appendix:main__parser_zlib_zlib}
\inputminted{zig}{../src/parser/zlib/zlib.zig}

\section{helper.zig}\label{appendix:main__parser_zlib_helper}
\inputminted{zig}{../src/parser/zlib/helper.zig}

\section{deflate.zig}\label{appendix:main__parser_zlib_deflate}
\inputminted{zig}{../src/parser/zlib/deflate.zig}

\section{huffmanTree.zig}\label{appendix:main__parser_zlib_huffmanTree}
\inputminted{zig}{../src/parser/zlib/huffmanTree.zig}

\section{noCompression.zig}\label{appendix:main__parser_zlib_noCompression}
\inputminted{zig}{../src/parser/zlib/noCompression.zig}

\section{dynamic.zig}\label{appendix:main__parser_zlib_dynamic}
\inputminted{zig}{../src/parser/zlib/dynamic.zig}

\section{fixed.zig}\label{appendix:main__parser_zlib_fixed}
\inputminted{zig}{../src/parser/zlib/fixed.zig}

\section{ast.zig}\label{appendix:main__parser_shared_ast}
\inputminted{zig}{../src/parser/shared/ast.zig}

\section{Settings.zig}\label{appendix:main__parser_shared_Settings}
\inputminted{zig}{../src/parser/shared/Settings.zig}

\section{level.zig}\label{appendix:main__parser_shared_level}
\inputminted{zig}{../src/parser/shared/level.zig}

\section{NodeOperations.zig}\label{appendix:main__parser_shared_NodeOperations}
\inputminted{zig}{../src/parser/shared/NodeOperations.zig}

\section{CommonContext.zig}\label{appendix:main__parser_shared_CommonContext}
\inputminted{zig}{../src/parser/shared/CommonContext.zig}

\section{pngDebug.zig}\label{appendix:main__pngDebug}
\inputminted{zig}{../src/pngDebug.zig}

