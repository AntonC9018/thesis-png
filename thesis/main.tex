\documentclass[a4paper,12pt]{report}
\usepackage{config}

% Description
\newcommand{\authorName}{CURMANSCHII Anton}
\newcommand{\thesisTitle}{PNG}
\newcommand{\uniGroupName}{IA1901}
\newcommand{\thesisType}{master}
\newcommand{\programulDeStudii}{master}
\newcommand{\identificatorulCursului}{0613.5 Informatică aplicată}

% Hardcoded for now
\newcommand{\anexeCount}{20}
\newcommand{\conferencesList}{I don't know what to write here}

\begin{document}

\input{foaie_de_titlu}

\clearpage
\tableofcontents

\clearpage
\unnumberedChapter{Lista Abrevierelor}
\begin{acronym}
  \acro{CI/CD}{Continuous Integration / Continuous Delivery}
  \acro{GUI}{Graphical User Interface}
  \acro{PNG}{Portable Network Graphics}
  \acro{I/O}{Input/Output}
  \acro{MVP}{Produs Minim Viabil}
  \acro{ICC}{International Color Consortium}
\end{acronym}


\clearpage
\unnumberedChapter{Adnotare}

\textbf{la teza de \thesisType ``\thesisTitle'', a studentului \authorName{}, grupa \uniGroupName{}, programul de studii \programulDeStudii.}

\textbf{Structura tezei.}
Teza constă din: Introducere, \total{num_chapters} capitole, Concluzii generale și recomandări, Bibliografie \bibliographyEntryCount{} titluri.
Textul de bază cuprinde \usefulPageCount{} de pagini și \anexeCount{} de anexe.

\textbf{Cuvinte-cheie:} \ac{PNG}

\textbf{Actualitatea.}
PNG este un format de imagini folosit pe scară largă pe Internet,
în dezoltarea aplicațiilor grafice, în jocuri, și în multe alte domenii.
Înțelegerea structurii formatului poate fi utilă pentru a-l putea extinde, 
a-l utiliza într-un mod mai eficient și acesta poate servi drept referință pentru 
crearea unor formate noi.

\textbf{Scopul și obiectivele cercetării}.



\textbf{Rezultatele preconizate și obținute} rezumă în: (1) (2) (3)

\textbf{Problemele importante rezolvate} sunt:

\textbf{Valoarea aplicativă.}

Rezultatele obținute au fost raportate la Conferința (-ele) \textbf{\conferencesList}.

% I think this one's required to be capitalized.
\unnumberedChapter{INTRODUCERE}

\markpage{usefulStuffBegin}

\textbf{Actualitatea și importanța temei.}

\textbf{Scopul și obiectivele.}

\textbf{Suportul metodologic și tehnologic.}

\textbf{Noutatea stiințifică/originalitatea.}

\textbf{Valoarea aplicativă.}

\textbf{Sumarul tezei.}

Primul capitol, \nameref{intro_chapter_title}, aduce informații generale.
Al doilea capitol, \nameref{architecture_chapter_title}, concretizează cerințele.
Al treilea capitol, \nameref{implementation_chapter_title}, urmează implementarea.


\chapter{Capitol introducere}\label{intro_chapter_title}

\chapterConclusionSection{intro_chapter_title}


\chapter{Arhitectura Aplicației}\label{architecture_chapter_title}

\chapterConclusionSection{architecture_chapter_title}


\chapter{Implementarea Sistemului}\label{implementation_chapter_title}

În continuare, se va prezenta implementarea unui decoder \ac{PNG} care va fi folosit pentru
a vizualiza formatul \ac{PNG} printr-o aplicație \ac{GUI}.
Decoderul va fi implementat în limbajul de programare Zig\cite{zig}
după specificația \ac{PNG}, versiunea 1.2\cite{png_spec}.
Interfața grafică va fi implementată folosind Raylib\cite{raylib}, tot în Zig.

Pentru a facilita interacțiunea cu fluxuri de date și a crea o abstracție în acest sens,
a fost dezvoltată o mică bibliotecă.
Experiența anterioară cu biblioteca \texttt{System.IO.Pipelines}\cite{system_io_pipelines}
din C\# a relevat mai multe avantaje în utilizarea unei astfel de abordări:
\begin{itemize}
  \item
  Implementarea corectă core să țină cont de toate cazurile-limită
  este facilitată de gestionarea complexității de către
  bibliotecă, cum ar fi alocarea și ștergerea buferelor,
  sau înfășurarea datelor pe mai multe segmente consecutive.

  \item
  Flexibilitatea codului crește, permițând implementarea unui automat finit
  și o rerulare din stări salvate anterior.

  \item
  Eficiența crescută prin soluționarea cazurilor de copiere a datelor în bufere temporare
  de o mărime neoptimă pentru cititor.

  \item
  Centralizarea logicii de citire într-un ciclu unificat,
  reducând duplicarea codului.

  \item
  Separarea completă a modulelor de citire și scriere,
  permițând procesarea datelor în fire separate,
  ceea ce elimină timpul pierdut la \ac{I/O} în timpul procesării.
\end{itemize}

Un prototip al unei biblioteci similare în Zig a fost dezvoltat,
omitând însă separarea modulelor de citire și scriere pentru a reduce complexitatea.
Această parte poate fi adăugată ulterior, nefiind esențială pentru un \ac{MVP}.

\section{Ideea aplicației la nivel înalt}

Având la bază o abordare explorativă, s-a decis programarea aplicației
pornind de la o imagine vagă a rezultatului dorit,
însă cu o direcție clară în ceea ce privește obiectivul general.

Având în vedere faptul că scopul principal al aplicației
este de a facilita explorarea structurii fișierelor \ac{PNG},
s-ar dori ca funcționalitatea să fie direct
influențată și determinată de această structură.
Designul interfeței grafice este conceput pentru a reflecta
caracteristicile specifice ale fișierelor \ac{PNG}.

Fișierele \ac{PNG} sunt compuse din secvențe denumite chunk-uri,
fiecare având o funcție specifică.
De exemplu, chunk-ul \texttt{IHDR} conține informații vitale despre imagine,
precum lățimea, înălțimea, numărul de biți per pixel ș.a.
Se intenționează ca interfața aplicației să pună
în evidență aceste chunk-uri, oferind detalii despre ele utilizatorilor
și permițând modificarea valorilor într-un mod
care nu afectează integritatea fișierului.
Informațiile ar fi prezentate per chunk, atunci când utilizatorul îl alege,
iar fiecare chunk trebuie să fie evidențiat, pentru a-l putea alege și vizualiza.

Pentru a sublinia aspectul de explorare a \textit{formatului} \ac{PNG},
și nu doar manipularea imaginilor în acest format,
se va include în aplicație un editor hexazecimal.
Acesta va prezenta valorile fiecărui octet și
va oferi reprezentări vizuale pentru a facilita distingerea diferitelor chunk-uri.
O caracteristică utilă a editorului va fi funcționalitatea
de a minimiza anumite chunk-uri, utilizând o iconiță dedicată,
deoarece multe dintre ele conțin date de pixeli
care nu sunt esențiale pentru înțelegerea formatului.

La selectarea unui chunk, vor fi afișate informații detaliate despre acesta,
incluzând numele, descrierea și lungimea.
Este crucial ca fiecare chunk să fie prezentat cu o structură specifică,
pentru a oferi o înțelegere completă a compoziției și funcționalității fișierelor \ac{PNG}.


\section{Imaginea inițială a implementării la nivel înalt}

În dezvoltarea software, este adesea practic să se abordeze problemele pe măsură ce apar.
Însă procesul de gândire și modul în care se ajunge la soluții
pot adăuga valoare dacă sunt împărtășite.
Deși nu există garanția că ideile înregistrate vor duce
la o soluție optimă sau chiar una funcțională,
și anumite probleme de implementare sunt ignorate la această etapă inițială,
această abordare reflectă natura evolutivă a dezvoltării software.

Excesul de planificare și gândire înainte de începerea scrierii codului
poate adesea conduce la un design incorect sau inferior.
Acest lucru se datorează faptului că în timpul programării pot apărea probleme neanticipate,
din cauza lipsei unei viziuni complete asupra întregului sistem.
Din acest motiv, planificarea detaliată a întregului sistem înainte de începerea dezvoltării
nu este întotdeauna cea mai înțeleaptă abordare.
Cu toate acestea, planificarea la nivel înalt a structurii aplicației,
ținând cont de cerințe și pe baza experienței,
este utilă pentru a descompune problema în subprobleme gestionabile
și pentru a începe implementarea unei soluții.

Pentru a reflecta această viziune, s-a stabilit ca aplicația
să fie împărțită în mai multe module esențiale:
\begin{itemize}
  \item 
  \textbf{Modulul de acces la fișiere după poziții absolute},
  care va gestiona cache-ul segmentelor vizualizate în prezent,
  ștergerea segmentelor nedorite din memorie și citirea datelor din fișier la necesitate.
  Acest modul este o abstracție cheie pentru a simplifica interacțiunea cu fișierele \ac{PNG}.

  \item
  \textbf{Arborele sintactic al fișierului \ac{PNG}},
  care ar trebui să păstreze în memorie doar informațiile despre
  chunk-urile vizualizate la un moment dat.
  Acesta ar permite accesul la informații structurate despre fișier
  și ar fi interfațat cu modulul de interacțiune cu utilizatorul
  pentru a indica ce segmente din fișier sunt vizualizate.

  \item
  \textbf{Parser-ul}, responsabil pentru transformarea datelor
  din fișier într-un arbore sintactic la cerere.
  Acest modul poate consta dintr-un set de funcții specifice pentru această transformare.

  \item
  \textbf{Modulul de interfață cu utilizatorul},
  care va folosi arborele sintactic al fișierului pentru
  a prezenta utilizatorului informații într-o formă atractivă și interactivă.
  Modulul va avea control asupra segmentelor din fișier care sunt vizualizate,
  permitând utilizatorului să actualizeze aceste segmente
  în funcție de chunk-urile afișate în interfață.
\end{itemize}

Așa cum s-a discutat, acest design inițial este un punct de plecare,
iar implicațiile utilizării acestuia urmează să fie analizate pe parcursul dezvoltării.


\section{Oportunitatea de abstracție a parser-ului}

Pe parcursul dezvoltării a parser-ului, indeosebi a funcțiilor de parsare a datelor din chunk-uri,
s-a observat o oportunitate de abstractizare a acestui cod.
Deoarece structura parser-ului este by design realizată ca o mașină de stări,
are sens să se facă o abstracție pentru a putea construi mașina acesta de stări mai ușor
fără a repeta logica.

Inițial, parser-ul se află într-o stare destinată validării a semnaturii fișierului \ac{PNG}.
Semnatura este o secvență specială de caractere care 
trebuie necesar să apare la începutul oricărui fișier \ac{PNG}.
După citire a semnăturii, parser-ul trece în starea începerii a citirii a unui chunk,
iar după ce începe a citi chunk-ul, trece la starea de citire a chunk-ului.
Acestă distincție există pentru a indica faptul că dacă fluxul de intrare
se termină în acest moment, atunci fișierul nu este complet și 
o eroare trebuie să fie indicată.

În timpul citirii a chunk-ului, parserul poate să se afle 
într-o stare specifică destinată fiecărui câmp al chunk-ului:
lungimea, tipul, datele, și suma de control.
Aceste stări sunt urmate unul de altul, adică valorile numerice
ale acestora pot fi derivate din valoarea trecută, de exemplu 
$ S_{date} = S_{lungime} + 1. $
Aceasta poate fi implementată în mod cel mai simplu can un \texttt{enum}
în orice limbaj de programare care le suportă, inclusiv Zig.

Un lucru asemănător se întâmplă la parsarea datelor unui chunk care are un format fix.
De exemplu, chunk-ul \texttt{IHDR} are un set de câmpuri fix, care sunt amplasate unul după altul.

În acestă logică însă se adaugă și ideea de validare mai meticuloasă a valorilor,
de exemplu, dimensiunile nu pot fi zero, iar \texttt{BitDepth} poate lua numai un set specific de valori
și acesta depinde de valoarea lui \texttt{ColorType}.

Încă un element este faptul că valorile ale lor, de exemplu, lungimea, tipul chunk-ului,
lățimea și înălțimea, precum și alte valorile parsate se dorește a fi păstrate undeva,
ca câmpuri ale unei structuri ce descrie nodul respectiv.

Deci, logica de parsare a unui câmp de obicei are următoarea formă:
\begin{enumerate}
\item
    Se citește numărul necesar de octeți din fluxul de intrare
        și se convertează acesta în tipul de date dorit (de exemplu, un \texttt{int}).
\item
    Se realizează validarea acestei valori.
    De exemplu, nu se admit valorile dimensiunilor egale cu zero.
    În unele cazuri eroarea nu este groaznică, poate fi înresitrată, iar parsarea poate fi continuată.
\item
    Salvarea valorii într-un câmp pe o structură respectivă.
\item
    Trecerea la următoarea stare.
\end{enumerate}

În plus, pentru debugging ar fi utilă o funcție care afișează drumul de stări curent,
adică, de exemplu, dacă parserul se află în starea parsării a unui chunk \texttt{IHDR}, 
și se află la etapa parsării câmpului \texttt{ColorType},
care este indicat printr-o altă variabilă de stare,
s-ar dori să se afișeze \texttt{Chunk(IHDR) ColorType}, sau ceva asemănător.

Ideea este ca acest proces s-ar putea fi abstractizat în loc de a fi duplicat:
\begin{enumerate}
\item
    În loc de mai multe variabile care să indice starea, aceasta poate fi păstrată ca
    o listă de numeri întregi, indicând un fel de drum pentru următoarea acțiune a parser-ului.
    Clar că drumul acesta ar fi deja generic și și-ar pierde informațiile despre tipul
    \texttt{enum}-ului care indică starea, ceea ce ar fi dezavantajos pentru debugging.
\item
    Logica de afișare a stării poate fi implementată destul de ușor, dacă există o listă de
    șiruri de caractere pentru fiecare index din drumul stării,
    și pentru fiecare valoare posibilă a stării la acel index,
    însă s-ar trebui atunci și să se modifice starea
    de pe poziție 0 de la \texttt{Chunk} la \texttt{IHDR}.
\item
    Ceea ce trebuie de făcut la diferite stări,
    și câtă memorie va fi necesară pentru a păstra nodul poate fi configurat separat,
    într-un mod mai declarativ.
\item
    Stările care se așteapă că vor seta anumite câmpuri
    pot indica offset-ul câmpului pentru ca sistemul să scrie valoarea acolo automat.
    Aceasta poate fi simplificat prin folosirea tehnicilor de metaprogramare oferite de Zig.
\item
    Fiecare stare ar trebui să declare o funcție de inițializare a nodului,
    o funcție de parsare și o funcție de validare a valorii.
    Aici s-ar putea oferi niște funcții de configurare pentru a partaja logica.
\end{enumerate}

Însă, realizarea acestui gând în starea curentă a dezvoltării n-ar fi înțeleaptă,
deoarece această oportunitate s-a observat la momentul
realizării a primului tip de chunk, \texttt{IHDR},
deci este posibil că nu s-ar generaliza bine pentru toate tipurile de chunk-uri.
Încă, s-a menționat deja anterior că această abordare reduce capacitatea de debugging.

\section{Zlib și Deflate}

Formatul \ac{PNG} folosește comprimarea datelor prin algoritmul Zlib.
Comprimarea se folosește pentru chunk-urile \texttt{zTXt} (text comprimat),
\texttt{iCCP} (profil \ac{ICC}), \texttt{IDAT} (datele pixelilor),
și posibil altele.
Pentru a înțelege problema mai bine, ar fi benefic să se înțeleagă cum funcționează algoritmul Zlib.
În plus, deoarece algorimul este parte din standardul \ac{PNG},
și structura acestuia poate fi decodificată și analizată,
ar fi benefic să se realizeze un fel de parser special pentru Zlib pentru a putea vizualiza nodurile Zlib
în mod bogat în interfață.
Din această cauză, s-a decis să se realizeze implementarea unui decoder Zlib de la zero.

Structura parserului folosită până acum poate fi aplicată și pentru formatul Zlib.
Singura diferență este că formatul Zlib este bazat pe biți, dar nu pe octeți.
Însă deoarece poziția pe biți absolut nu ține de gestionarea buferilor,
componenta \texttt{pipelines} care realizează fluxul de date nu va trebui să fie modificată.
Starea parserului Zlib poate să țină cont de poziția pe biți ca o variabilă privată, deoarece
acest concept nu se revarsă la procesarea \ac{PNG}.
Însă, poziția pe biți ar trebuie să fie utilă pentru vizualizare a formatului.
Acesta nu este o problemă, deoarece interfața are acces la starea privată a parser-ului.

Mai complicat conceptual este sistemul de decompresie,
deoarece acesta trebuie să păstreze octeții decodificate pentru a se referi la ei
în procesul de decompresie, până la 32 KB de date.
Pentru prototip, a fost realizată o abordare simplă --- se păstrează toți octeții într-un bufer dinamic.

\subsection{Testarea}

Problema legată de testare este faptul că, deoarece programul este orientat
la decompresie și nici nu realizează un compresor,
este dificit să se genereze niște date pentru teste.

Sunt două variante care ar putea fi folosie:
\begin{enumerate}
    \item
        Se poate folosi un compresor existent, adică o altă librarie, pentru a genera datele.
        Minusul acestei abordări este faptul că codul de generare a datelor atunci va exista
        ca un modul independent și nu poate fi ușor folosită abordarea "kitchen sink", adică
        compresia dintr-o structură de date, și urmând-o decompresia, după ce să se verifice
        dacă rezultatul este echivalent cu structura de date originală.
        Însă, testarea de așa fel n-ar fi de neatins --- cu o anumită masură de lucru,
        poate fi realizat un sistem care permite testele declarative folosind așa abordare.
        Pentru prototipul dat însă s-a decis că această abordare ar fi prea consumătoare de timp.
    \item
        Se poate găsi niște date de test, și a le folosi pentru a face testarea
        la întregul sistem, cu diferite intrări, fără a înțelege toate nuanțele ale datelor de intrare.
        Adică, dacă se găsește o eroare pentru un samplu corect -- testul se eșuează,
        și invers, pentru un samplu incorect decompresia trebuie să se eșueze.
        Una din referințe \cite{gzip_impl} folosește așa abordare pentru teste negative,
        însă are datele pentru formatul gzip, dar nu zlib, din care cauză acestea nu au putut fi folosite.
\end{enumerate}

Ca atare există și încă o abordare -- să nu se facă testarea la modulul zlib direct.
Pentru prototip, această abordare este cea mai aplicabilă pentru a putea sălva timpul.

Testarea indirectă oricum va fi folosită la testarea intrărilor diferite ale formatului \ac{PNG},
deoarece acesta numaidecât folosește zlib pentru chunk-urile \texttt{IDAT} care trebuie să fie prezente
în orice exemplu de fișier \ac{PNG}.

\section{Procesarea erorilor}

La implementarea inițială a prototipului s-a observat că erorile pot să fie semnalizate
la momente diferite de detectare a lor și unele din ele pot avea niște date asociate
care trebuie să fie accesibile de utilizator, de dorit într-un mod consistent.

De exemplu, când se citește un număr întreg de 4 octeți din fluxul de intrare,
avem 3 posibilități diferite de implementare a acestei idei.
Acestea implică transferul diferit al contextului de eroare și
urmează în poziții diferite înregistrate ale secvenței curente de intrare.

\begin{minted}{zig}
pub fn impl(context: *Context) !void
{
    // ...

    switch (context.state.action)
    {
        // ...

        .Number =>
        {
            // Read the int, modify the stream
            const number = try pipelines.readInt(context.sequence);

            // Save the context
            context.state.number = number;

            // Validate
            if (number == 256)
            {
                return error.CannotBe256;
            }
        },

        // ...
    }
}

pub fn callSite()
{
    // ...

    impl(&context)
    catch |err|
    {
        switch (err)
        {
            error.CannotBe256 =>
            {
                // If multiple states can result in this error,
                // need to check which state we're in.
                switch (context.state.action)
                {
                    // ...

                    .Number =>
                    {
                        std.debug.print("The number {} is invalid while parsing Number\n", .{
                            context.state.number
                        });
                    },

                    // ...
                }

                return error.ParsingFailed;
            },
        }
    };
}
\end{minted}

O altă variantă ar fi putea următoarea, unde octeții citiți
se consumă numai dacă nu s-a observat o eroare.

\begin{minted}{zig}
pub fn impl(context: *Context) !void
{
    // ...

    switch (context.state.action)
    {
        // ...

        .Number =>
        {
            // Read the int, but do not consume the stream
            const number = try pipelines.peekInt(context.sequence);

            // Save the context
            context.state.number = number.value;

            // Validate
            if (number.value == 256)
            {
                return error.CannotBe256;
            }

            // Consume the read bytes if the result is valid.
            number.apply(context);
        },

        // ...
    }
}
\end{minted}

Se mai poate transmite eroarea într-un mod diferit.
Următoarea abordare permite înregistrarea mai multor erori.
Pentru moment, așa ceva nu se folosește, însă tot este o abordare validă.

\begin{minted}{zig}
pub fn impl(context: *Context) !void
{
    // ...

    switch (context.state.action)
    {
        // ...

        .Number =>
        {
            // Read the int, modify the stream
            const number = try pipelines.readInt(context.sequence);

            // Validate
            if (number == 256)
            {
                context.state.addError(.{
                    .err = error.CannotBe256,
                    .context = number,
                });
            }
            else
            {
                // Can use the type system to semantically indicate validity.
                context.state.number = ValidNumber
                {
                    .value = number,
                };
            }
        },

        // ...
    }
}

pub fn callSite()
{
    // ... 

    const errorScope = context.state.errorScope();

    impl(&context);
    catch |err|
    {
        // Here, only memory allocation related errors and the NotEnoughBytes error is possible.
        // ...
    };

    if (errorScope.errorsHappened()) |errors|
    {
        for (errors) |e|
        {
            switch (e.err)
            {
                // ...

                case error.CannotBe256 =>
                {
                    const numberActuallyRead = try coerce(u32, e.context);
                    std.debug.assert(numberActuallyRead == 256);
                },
            }
        }
    }
}
\end{minted}


\section{Complicațiile asociate cu citirea chunk-ului \texttt{IDAT}}

Posibilitatea de a putea păstra informațiile despre originea fiecărui "nod",
adică poziția a acestuia absolută din fișier,
precum și posibilitatea de a trata fluxul de date ca unul linear nu sunt direct compatibile
atunci când fluxul de date poate "sări", adică atunci când pozițiile absolute
între diferitele segmente nu sunt consecutive.
Deoarece unul singur nod poate să se afle la marginea a două segmente (potențial mai mult ca două),
ideea că locația fiecărui nod poate fi descrisă de locația lui absolută în fișier și
lungimea lui deja nu se va aplica.

Cu toate că pentru noduri regulare din formatul PNG așa ceva nu este posibil,
chunk-ul \texttt{IDAT} este special în acest sens.
Toate chunk-urile acestea conțin unul singur stream Zlib partajat,
iar parserul PNG se consideră incorect dacă nu realizează corect
orice distribuție a fluxului Zlib între chunk-uri.
Adică parserul PNG nu poate presupune de exemplu că blocul Zlib va termina de fiecare dată
împreună cu chunk-ul \texttt{IDAT} în care se află.
De fapt, este posibilă situația că biții ultimului bit au rămas necitite până la capăt
în primul chunk \texttt{IDAT}, continuându-se în următorul chunk.

Deoarece arborele Huffman din specificația Zlib permit lungimea maximă de 16 biți pentru coduri,
iar programul trebuie să considere aceste coduri ca noduri separate,
și acestea pot să se afle la offset-uri de biți nealiniate cu granițele octeților,
în cel mai rău caz se poate întâmpla ca unul singur nod să se afle în 3 chunk-uri în același timp.
De exemplu, primul bit poate să se afle la sfârșitul primului chunk,
următoarele 8 biți pot să se afle în întregul următorul chunk, dacă acesta are lungimea 1, ce este posibil,
și atunci se va termina la începutul celui de-al treilea chunk.

Pentru a putea păstra ideea de a putea procesa datele folosind secvențele,
de părca acestea erau consecutive, ar trebui să se include acele părți trecute necitite până la capăt
la începutul secvenței, când se realizează procesarea fluxului Zlib.

Prima problema era că secvența trebuia să se includă doar segmentele din manager de bufer principal,
folosind de către cititor.
De fapt, segmentele erau păstrate ca index-urile în tabloul de segmente, cu un offset de bază.
Ca să devină posibil de inclus niște segmente dinafara buferilor principali la începutul secvenței,
modul acesta de adresare a fost schimbat la o listă înlănțuită.
Astfel, este posibil să seteze segmentul adăugator ca primul segment din secvență, urmându-l cu
primul segment din secvența inițială, pentru a crea secvența nouă.

Următoarea problema era că implementarea inițială a secvențelor din modulul \texttt{pipelines} presupunea
că toate segmentele care se află între primul și ultimul segment se includ în secvența în întregime.
Însă, secvența poate avea ca prima poziție segmentul inițial la un offset.
Deoarece el este predestinat să devină al doilea segment după adăugare a primului segment adăugător,
trebuie s-a hotărât să-i miște buferul de început, aplicând offset-ul.

Această soluție nu se simte curată.
Sunt alte abordări puțin mai complicate, dar care potențial vor face implementarea arborelui mai ușoară.
Deoarece acele segmente de început pentru moment sunt temporare,
nodurile din arbore nu pot să se refere la acestea, iar pozițiile din acestea pot să nu existe în buferi la momentul curent.

Poate o abordare mai bună ar fi ca acele segmente veche să se păstreze în lista buferilor,
pentru a putea să se adreseze la acestea în secvențe,
și ca segmentele din secvențe să-și poată specifica offset-uri,
cu însele date păstrate separat, doar în buferi principali.
Atunci ar trebui să se adauge și un fel de "comsumed position hint" la cititorul,
ca el să păstreze segmentele care încă nu s-au citit până la capăt.

De fapt, așa idee se folosește și în biblioteca \texttt{System.IO.Pipelines} din C\#,
însă la implementarea inițială nu era clar de ce ar fi necesară această abordare.
După ce s-a întâlnit problema care se rezolvă folosind această idee, s-a clarificat și sensul ei.

% Probabil, am să schimb implementarea atunci când încep cu arborele.

\chapterConclusionSection{implementation_chater_title}


\unnumberedChapter{Concluziile Finale și Recomandările}


\newpage
\markpage{usefulStuffEnd}


% Bibliography
\bibliographystyle{plain}
\bibliography{bibliography}
\addcontentsline{toc}{chapter}{\bibname}

% Appendices
\appendix

% Number with arabic numbers instead of Roman
\renewcommand{\thechapter}{\arabic{chapter}}
% Prepend Anexa to section names, center them
\titleformat{\section}[block]{\normalfont\normalsize\bfseries\filcenter}{Anexa \thesection~}{0pt}{}

% Every section on new page
% \newcommand{\sectionbreak}{\clearpage}

% Since we've got just a single chapter in the appedices,
% but which is also the name of the Appendix chapter, it should be omitted.
% Makes little sense, but ok I guess.
\setcounter{chapter}{1}

\unnumberedChapter{Anexe}
% insert appendices here

\end{document}
% vim: fdm=syntax
