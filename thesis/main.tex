\documentclass[a4paper,12pt]{report}
\usepackage{config}

% Description
\newcommand{\authorName}{CURMANSCHII Anton}
\newcommand{\thesisTitle}{PNG}
\newcommand{\uniGroupName}{IA1901}
\newcommand{\thesisType}{master}
\newcommand{\programulDeStudii}{master}
\newcommand{\identificatorulCursului}{0613.5 Informatică aplicată}

% Hardcoded for now
\newcommand{\anexeCount}{20}
\newcommand{\conferencesList}{SESIUNEA NAŢIONALĂ CU PARTICIPARE INTERNAȚIONALĂ DE COMUNICĂRI ŞTIINŢIFICE STUDENŢEŞTI, EDIŢIA A XXVIII-A}

\begin{document}

\input{foaie_de_titlu}

\clearpage
\tableofcontents

\clearpage
\unnumberedChapter{Lista Abrevierelor}
\begin{acronym}
  \acro{CI/CD}{Continuous Integration / Continuous Delivery}
  \acro{GUI}{Graphical User Interface}
  \acro{PNG}{Portable Network Graphics}
  \acro{I/O}{Input/Output}
  \acro{MVP}{Produs Minim Viabil}
  \acro{ICC}{International Color Consortium}
\end{acronym}


\clearpage
\unnumberedChapter{Adnotare}

\textbf{la teza de \thesisType ``\thesisTitle'', a studentului \authorName{}, grupa \uniGroupName{}, programul de studii \programulDeStudii.}

\textbf{Structura tezei.}
Teza constă din: Introducere, \total{num_chapters} capitole, Concluzii generale și recomandări, Bibliografie \bibliographyEntryCount{} titluri.
Textul de bază cuprinde \usefulPageCount{} de pagini și \anexeCount{} de anexe.

\textbf{Cuvinte-cheie:}
\textit{\ac{PNG}, \ac{Zlib}, \ac{Deflate}, format de fișier, arbore sintactic, aplicație pentru vizualizare.}

\textbf{Actualitatea.}

PNG este un format de imagini folosit pe scară largă pe Internet,
în dezoltarea aplicațiilor grafice, precum și în alte diverse domenii.
Înțelegerea structurii formatului poate fi utilă pentru a-l putea extinde, 
a-l utiliza într-un mod mai eficient și acesta poate servi drept referință pentru 
crearea unor formate noi.

\textbf{Scopul și obiectivele cercetării}.

Lucrarea de față are scopul educațional -- să facă cunoștința cu structura formatului \ac{PNG}.
Obiectivele tezei constă în explorarea formatului creând o aplicație grafică de vizualizare.

Scopul tezei explicit \textit{nu constă} în afișarea imaginii pe ecran, focusând anume la structura formatului.

\textbf{Rezultatele preconizate și obținute} rezumă în: 
(1) studierea și înțelegerea formatului \ac{PNG} și a formaturilor de compresie asociate 
(2) implementarea unui parser în cod
(3) implementarea unei aplicații grafice pe baza parser-ului.

\textbf{Problemele importante rezolvate} sunt: înțelegerea slabă a formatului \ac{PNG}.

\textbf{Valoarea aplicativă.} Ca rezultat a fost implementată o aplicație care poate fi folosită pentru vizualizare a formatului \ac{PNG}.

Rezultatele obținute au fost raportate la Conferința \textbf{\conferencesList}.

% I think this one's required to be capitalized.
\unnumberedChapter{INTRODUCERE}

\markpage{usefulStuffBegin}

\textbf{Actualitatea și importanța temei.}

Formatul \ac{PNG} este utilizat pe scară largă în numeroase domenii, incluzând majoritatea aplicațiilor
web, aplicații grafice care salvează sau încarcă imagini din fișiere, precum și în dezvoltarea de jocuri.
PNG este un format adaptiv și extensibil, având o structură băzată pe chunk-uri, versionate separat unul
de altul. Formatul include, de asemenea, mecanisme pentru asigurarea integrității datelor, precum
octeții elementului cyclic redundancy check (CRC).

Reieșind din toate acestea, formatul \ac{PNG} merită să se învețe pentru a manipula eficient fișierele de
acest format, pentru a putea extinde formatul prin niște chunk-uri personalizate, și pentru a afla despre
metodele de asigurare a integrității, precum și despre algoritmii de compresie folosite ca parte din PNG
(Zlib). Aceste idei pot ajuta și la crearea unor formate noi de fișier, nu neapărat de imagine.

\textbf{Scopul și obiectivele.}

Lucrarea de față are scopul educațional -- să facă cunoștința cu structura formatului \ac{PNG} și a
formatului integrat de compresie \ac{Zlib}. Pentru aceasta s-a decis să se creeze o interfață grafică care
să permită explorarea vizuală a formatului \ac{PNG}, creând un parser și oarecare alte instrumente necesare în proces.


\textbf{Suportul metodologic și tehnologic.}

Structura formatului \ac{PNG} și a formaturilor de compresie integrate \ac{Zlib} și Deflate
a fost studiată din specificațiile acestora \cite{png_spec} \cite{zlib_spec} \cite{deflate_spec}.
Programul a fost implementat în limbajul de programare Zig \cite{zig} care a fost învățat prin documentație.
Pentru implementarea formatului Deflate ca referință a fost într-o măsură scăzută folosit codul librăriei uzlib \cite{gzip_impl}.
A fost folosită librăria Raylib \cite{raylib} drept librăria grafică.

\textbf{Noutatea stiințifică/originalitatea.}

Cu toate că există mai multe librării \ac{PNG},
scopul acestei teze diferă de scopul librăriilor \ac{PNG} obișnuite,
care este reprezentarea imaginii pe ecran,
dar nu explorarea formatului de fișier sau construirea arborelui sintactic.
Teza explicit nu are scopul de a afișa imaginea pe ecran.

\textbf{Valoarea aplicativă.}

Aplicația obținută poate fi folosită pentru a-și face cunoștința cu formatul de fișier \ac{PNG}.


\textbf{Sumarul tezei.}

Primul capitol, \nameref{intro_chapter_title}, aduce informații generale.
Al doilea capitol, \nameref{architecture_chapter_title}, concretizează cerințele.
Al treilea capitol, \nameref{implementation_chapter_title}, urmează implementarea.


\chapter{Capitol introducere}\label{intro_chapter_title}

\chapterConclusionSection{intro_chapter_title}


\chapter{Arhitectura Aplicației}\label{architecture_chapter_title}

\chapterConclusionSection{architecture_chapter_title}


\chapter{Implementarea Sistemului}\label{implementation_chapter_title}

În continuare, se va prezenta implementarea unui decoder \ac{PNG} care va fi folosit pentru
a vizualiza formatul \ac{PNG} printr-o aplicație \ac{GUI}.
Decoderul va fi implementat în limbajul de programare Zig\cite{zig}
după specificația \ac{PNG}, versiunea 1.2\cite{png_spec}.
Interfața grafică va fi implementată folosind Raylib\cite{raylib}, tot în Zig.

Pentru a facilita interacțiunea cu fluxuri de date și a crea o abstracție în acest sens,
a fost dezvoltată o mică bibliotecă.
Experiența anterioară cu biblioteca \texttt{System.IO.Pipelines}\cite{system_io_pipelines}
din C\# a relevat mai multe avantaje în utilizarea unei astfel de abordări:
\begin{itemize}
  \item
  Implementarea corectă core să țină cont de toate cazurile-limită
  este facilitată de gestionarea complexității de către
  bibliotecă, cum ar fi alocarea și ștergerea buferelor,
  sau înfășurarea datelor pe mai multe segmente consecutive.

  \item
  Flexibilitatea codului crește, permițând implementarea unui automat finit
  și o rerulare din stări salvate anterior.

  \item
  Eficiența crescută prin soluționarea cazurilor de copiere a datelor în bufere temporare
  de o mărime neoptimă pentru cititor.

  \item
  Centralizarea logicii de citire într-un ciclu unificat,
  reducând duplicarea codului.

  \item
  Separarea completă a modulelor de citire și scriere,
  permițând procesarea datelor în fire separate,
  ceea ce elimină timpul pierdut la \ac{I/O} în timpul procesării.
\end{itemize}

Un prototip al unei biblioteci similare în Zig a fost dezvoltat,
omitând însă separarea modulelor de citire și scriere pentru a reduce complexitatea.
Această parte poate fi adăugată ulterior, nefiind esențială pentru un \ac{MVP}.

\section{Ideea aplicației la nivel înalt}

Având la bază o abordare explorativă, s-a decis programarea aplicației
pornind de la o imagine vagă a rezultatului dorit,
însă cu o direcție clară în ceea ce privește obiectivul general.

Având în vedere faptul că scopul principal al aplicației
este de a facilita explorarea structurii fișierelor \ac{PNG},
s-ar dori ca funcționalitatea să fie direct
influențată și determinată de această structură.
Designul interfeței grafice este conceput pentru a reflecta
caracteristicile specifice ale fișierelor \ac{PNG}.

Fișierele \ac{PNG} sunt compuse din secvențe denumite chunk-uri,
fiecare având o funcție specifică.
De exemplu, chunk-ul \texttt{IHDR} conține informații vitale despre imagine,
precum lățimea, înălțimea, numărul de biți per pixel ș.a.
Se intenționează ca interfața aplicației să pună
în evidență aceste chunk-uri, oferind detalii despre ele utilizatorilor
și permițând modificarea valorilor într-un mod
care nu afectează integritatea fișierului.
Informațiile ar fi prezentate per chunk, atunci când utilizatorul îl alege,
iar fiecare chunk trebuie să fie evidențiat, pentru a-l putea alege și vizualiza.

Pentru a sublinia aspectul de explorare a \textit{formatului} \ac{PNG},
și nu doar manipularea imaginilor în acest format,
se va include în aplicație un editor hexazecimal.
Acesta va prezenta valorile fiecărui octet și
va oferi reprezentări vizuale pentru a facilita distingerea diferitelor chunk-uri.

La selectarea unui chunk, vor fi afișate informații detaliate despre acesta,
incluzând numele, descrierea și lungimea.
Este crucial ca fiecare chunk să fie prezentat cu o structură specifică,
pentru a oferi o înțelegere completă a compoziției și funcționalității fișierelor \ac{PNG}.


\section{Imaginea inițială a implementării la nivel înalt}

În dezvoltarea software, este adesea practic să se abordeze problemele pe măsură ce apar.
Însă procesul de gândire și modul în care se ajunge la soluții
pot adăuga valoare dacă sunt împărtășite.
Deși nu există garanția că ideile înregistrate vor duce
la o soluție optimă sau chiar una funcțională,
și anumite probleme de implementare sunt ignorate la această etapă inițială,
această abordare reflectă natura evolutivă a dezvoltării software.

Excesul de planificare și gândire înainte de începerea scrierii codului
poate adesea conduce la un design incorect sau inferior.
Acest lucru se datorează faptului că în timpul programării pot apărea probleme neanticipate,
din cauza lipsei unei viziuni complete asupra întregului sistem.
Din acest motiv, planificarea detaliată a întregului sistem înainte de începerea dezvoltării
nu este întotdeauna cea mai înțeleaptă abordare.
Cu toate acestea, planificarea la nivel înalt a structurii aplicației,
ținând cont de cerințe și pe baza experienței,
este utilă pentru a descompune problema în subprobleme gestionabile
și pentru a începe implementarea unei soluții.

Pentru a reflecta această viziune, s-a stabilit ca aplicația
să fie împărțită în mai multe module esențiale:
\begin{itemize}
  \item 
  \textbf{Modulul de acces la fișiere după poziții absolute},
  care va gestiona cache-ul segmentelor vizualizate în prezent,
  ștergerea segmentelor nedorite din memorie și citirea datelor din fișier la necesitate.
  Acest modul este o abstracție cheie pentru a simplifica interacțiunea cu fișierele \ac{PNG}.

  \item
  \textbf{Arborele sintactic al fișierului \ac{PNG}},
  care ar trebui să păstreze în memorie doar informațiile despre
  chunk-urile vizualizate la un moment dat.
  Acesta ar permite accesul la informații structurate despre fișier
  și ar fi interfațat cu modulul de interacțiune cu utilizatorul
  pentru a indica ce segmente din fișier sunt vizualizate.

  \item
  \textbf{Parser-ul}, responsabil pentru transformarea datelor
  din fișier într-un arbore sintactic la cerere.
  Acest modul poate consta dintr-un set de funcții specifice pentru această transformare.

  \item
  \textbf{Modulul de interfață cu utilizatorul},
  care va folosi arborele sintactic al fișierului pentru
  a prezenta utilizatorului informații într-o formă atractivă și interactivă.
  Modulul va avea control asupra segmentelor din fișier care sunt vizualizate,
  permitând utilizatorului să actualizeze aceste segmente
  în funcție de chunk-urile afișate în interfață.
\end{itemize}

Așa cum s-a discutat, acest design inițial este un punct de plecare,
iar implicațiile utilizării acestuia urmează să fie analizate pe parcursul dezvoltării.


\section{Oportunitatea de abstracție a parser-ului}

Pe parcursul dezvoltării a parser-ului, indeosebi a funcțiilor de parsare a datelor din chunk-uri,
s-a observat o oportunitate de abstractizare a acestui cod.
Deoarece structura parser-ului este proiectată ca o mașină de stări,
are sens să fie realizată o abstracție pentru a putea construi mașina acesta de stări mai ușor
fără a repeta logica.

Inițial, parser-ul se află într-o stare destinată validării a semnăturii fișierului \ac{PNG}.
Semnătura este o secvență specială de caractere care 
trebuie necesar să apare la începutul oricărui fișier \ac{PNG}.
După citire a semnăturii, parser-ul trece la starea de citire a chunk-ului.
Parsesul trebuie să mai noteze dacă a început să citească următorul chunk.
Acesta este important pentru a indica faptul că dacă fluxul de intrare
se termină după ce s-a început citirea, atunci fișierul nu este complet și 
o eroare trebuie să fie semnalizată.

În timpul citirii a chunk-ului, parserul poate să se afle 
într-o stare specifică destinată fiecărui câmp al chunk-ului:
lungimea, tipul, datele, și suma de control.
Aceste stări sunt urmate unul de altul, adică valorile numerice
ale acestora pot fi derivate din valoarea trecută, de exemplu 
$ S_{date} = S_{lungime} + 1. $
Aceasta poate fi implementată în mod cel mai simplu can un \texttt{enum}
în orice limbaj de programare care le suportă, inclusiv Zig.

Un lucru asemănător se întâmplă la parsarea datelor unui chunk care are un format fix.
De exemplu, chunk-ul \texttt{IHDR} are un set de câmpuri fix, care sunt amplasate unul după altul.

În acestă logică însă se adaugă și ideea de validare mai meticuloasă a valorilor,
de exemplu, dimensiunile nu pot fi zero, iar \texttt{BitDepth} poate lua numai un set specific de valori
și acesta depinde de valoarea lui \texttt{ColorType}.

Încă un element este faptul că valorile ale lor, de exemplu, lungimea, tipul chunk-ului,
lățimea și înălțimea, precum și alte valorile parsate se dorește a fi păstrate undeva,
ca câmpuri ale unei structuri ce descrie nodul respectiv.
În structura finală a aplicației, aceste valori au fost amplasate în noduri ale unui arbore sintactic.

Deci, logica de parsare a unui câmp de obicei are următoarea formă:
\begin{enumerate}
\item
    Se citește numărul necesar de octeți din fluxul de intrare
        și se convertează aceștia în tipul de date dorit (de exemplu, un \texttt{int}).
\item
    Se realizează validarea acestei valori.
    De exemplu, nu se admit valorile dimensiunilor egale cu zero.
    În unele cazuri eroarea nu este groaznică, poate fi înresitrată, iar parsarea poate fi continuată.
\item
    Salvarea valorii într-un câmp pe o structură (sau într-un nod, în structura finală a aplicației).
\item
    Trecerea la următoarea stare.
\end{enumerate}

În plus, pentru debugging ar fi utilă o funcție care afișează drumul de stări curent,
adică, de exemplu, dacă parserul se află în starea parsării a unui chunk \texttt{IHDR}, 
și se află la etapa parsării câmpului \texttt{ColorType},
care este indicat printr-o altă variabilă de stare,
s-ar dori să se afișeze \texttt{Chunk(IHDR) ColorType}, sau ceva asemănător.

Ideea este ca acest proces s-ar putea fi abstractizat în loc de a fi duplicat:
\begin{enumerate}
\item
    În loc de mai multe variabile care să indice starea, aceasta poate fi păstrată ca
    o listă de numeri întregi, indicând un fel de drum pentru următoarea acțiune a parser-ului.
    Clar că drumul acesta ar fi deja generic și și-ar pierde informațiile despre tipul
    \texttt{enum}-ului care indică starea, ceea ce ar fi dezavantajos pentru debugging.
\item
    Logica de afișare a stării poate fi implementată destul de ușor, dacă există o listă de
    șiruri de caractere pentru fiecare index din drumul stării,
    și pentru fiecare valoare posibilă a stării la acel index,
    însă s-ar trebui atunci și să se modifice starea
    de pe poziție 0 de la \texttt{Chunk} la \texttt{IHDR}.
\item
    Ceea ce trebuie de făcut la diferite stări,
    și câtă memorie va fi necesară pentru a păstra nodul poate fi configurat separat,
    într-un mod mai declarativ.
\item
    Stările care se așteapă că vor seta anumite câmpuri
    pot indica ofsetul câmpului pentru ca sistemul să scrie valoarea acolo automat.
    Aceasta poate fi simplificat prin folosirea tehnicilor de metaprogramare oferite de Zig.
\item
    Fiecare stare ar trebui să declare o funcție de inițializare a nodului,
    o funcție de parsare și o funcție de validare a valorii.
    Aici s-ar putea oferi niște funcții de configurare pentru a partaja logica.
\end{enumerate}

Însă, realizarea acestui gând în starea inițială a dezvoltării n-ar fi înțeleaptă,
deoarece această oportunitate s-a observat la momentul
realizării a primului tip de chunk, \texttt{IHDR},
deci este posibil că nu s-ar generaliza bine pentru toate tipurile de chunk-uri.
Încă, s-a menționat deja anterior că această abordare reduce capacitatea de debugging.

În structura finală a aplicației s-a observat că chunk-urile au o structură destul de diferită unul de altul.
Cu toate că abordarea aceasta s-ar putea fi aplicată la unele chunk-uri,
integrarea acestui subsistem cu logica obișnuită procedurală a celorlalte chunk-uri
ar fi complicată și ar reduce semnificativ meritul acestei abordări. 

\section{Zlib și Deflate}

Formatul \ac{PNG} folosește comprimarea datelor prin algoritmul Zlib.
Comprimarea se folosește pentru chunk-urile \texttt{zTXt} (text comprimat),
\texttt{iCCP} (profil \ac{ICC}), \texttt{IDAT} (datele pixelilor), precum și altele.
Pentru a înțelege problema mai bine, ar fi benefic să se înțeleagă cum funcționează algoritmul Zlib.
În plus, deoarece algorimul este parte din standardul \ac{PNG},
și structura acestuia poate fi decodificată și analizată,
ar fi benefic să se realizeze un fel de parser special pentru Zlib pentru a putea vizualiza nodurile Zlib
în mod bogat în interfață.
Din această cauză, s-a decis să se realizeze implementarea unui decoder Zlib de la zero.

Structura parserului menționată până acum poate fi aplicată și pentru formatul Zlib.
Singura diferență este că formatul Zlib este bazat pe biți, dar nu pe octeți.
Însă deoarece poziția pe biți absolut nu ține de gestionarea buferilor,
componenta \texttt{pipelines} care realizează fluxul de date nu va trebui să fie modificată.
Starea parserului Zlib poate să țină cont de poziția pe biți ca o variabilă privată, deoarece
acest concept nu se revarsă la procesarea \ac{PNG}.
Însă, poziția pe biți ar trebuie să fie utilă pentru vizualizare a formatului.

În structura finală a aplicației, poziția pe biți a componentelor din fluxul de date a fost sălvată la crearea nodurilor.

Mai complicat conceptual este sistemul de decompresie,
deoarece acesta trebuie să păstreze octeții decodificate pentru a putea referi la acestea
în procesul de decompresie, până la 32 KB de date.

A fost realizată o abordare simplă --- se păstrează toți octeții într-un bufer dinamic.
S-ar putea aplica o abordare mai complexă, însă acest element al programului
nu este atât de important sau interesant din punct de vedere a formatului pentru a merita optimizarea.

\subsection{Testarea}

Problema legată de testare este faptul că, deoarece programul este orientat
la decompresie și nici nu realizează un compresor,
este dificit să se genereze niște date pentru teste.

Sunt două variante care ar putea fi folosie:
\begin{enumerate}
    \item
        Se poate folosi un compresor existent, adică o altă librarie, pentru a genera datele.
        Minusul acestei abordări este faptul că codul de generare a datelor atunci va exista
        ca un modul independent și nu poate fi ușor folosită abordarea "kitchen sink", adică
        compresia dintr-o structură de date, și urmând-o decompresia, după ce să se verifice
        dacă rezultatul este echivalent cu structura de date originală.
        Însă, testarea de așa fel n-ar fi de neatins --- cu o anumită masură de lucru,
        poate fi realizat un sistem care permite testele declarative folosind așa abordare.
        Pentru prototipul dat însă s-a decis că această abordare ar fi prea consumătoare de timp.
    \item
        Se poate găsi niște date de test, și a le folosi pentru a face testarea
        la întregul sistem, cu diferite intrări, fără a înțelege toate nuanțele ale datelor de intrare.
        Adică, dacă se găsește o eroare pentru un samplu corect -- testul se eșuează,
        și invers, pentru un samplu incorect decompresia trebuie să se eșueze.
        Una din referințe \cite{gzip_impl} folosește așa abordare pentru teste negative,
        însă are datele pentru formatul gzip, dar nu zlib, din care cauză acestea nu au putut fi folosite.
\end{enumerate}

De fapt există și încă o abordare -- să nu facă testarea la modulul zlib direct.
Pentru prototip, această abordare este cea mai aplicabilă pentru a putea sălva timpul.

Testarea indirectă oricum va fi folosită la testarea intrărilor diferite ale formatului \ac{PNG},
deoarece acesta numaidecât folosește Zlib pentru chunk-urile \texttt{IDAT} care trebuie să fie prezente
în orice exemplu de fișier \ac{PNG}.

În plus, decodificarea deja este verificată conform câmpului de suma de control Adler32,
care în cazul dacă corespunde valorii acestei sume de control calculate pe baza biților decodificați,
indică probabilitatea înaltă că fișierul a fost decodificat corect. 
Notez că probabilitatea este înaltă, dar nu categorică din cazul că aceasta este într-un fel o funcție hash
care nu dau garanții exacte față de integritate, ci doar o certitudine înaltă.


\section{Procesarea erorilor}

La implementarea inițială a prototipului s-a observat că erorile pot să fie semnalizate
la momente diferite de detectare a lor și unele din ele pot avea niște date asociate
care trebuie să fie accesibile de utilizator, de dorit într-un mod consistent.

De exemplu, când se citește un număr întreg de 4 octeți din fluxul de intrare,
avem 3 posibilități diferite de implementare a acestei idei.
Acestea implică transferul diferit al contextului de eroare și
urmează în poziții diferite înregistrate ale secvenței curente de intrare.

\begin{minted}{zig}
pub fn impl(context: *Context) !void
{
    // ...

    switch (context.state.action)
    {
        // ...

        .Number =>
        {
            // Citirea unui întreg, modificarea fluxului.
            const number = try pipelines.readInt(context.sequence());

            // Salvarea valorii pe context.
            context.state.number = number;

            // Validarea.
            if (number == 256)
            {
                return error.CannotBe256;
            }
        },

        // ...
    }
}

pub fn callSite()
{
    // ...

    impl(&context)
    catch |err|
    {
        switch (err)
        {
            error.CannotBe256 =>
            {
                // Dacă mai multe stări pot produce această eroare,
                // Trebuie să se verifice în care stare se află parserul.
                switch (context.state.action)
                {
                    // ...

                    .Number =>
                    {
                        std.debug.print("The number {} is invalid while parsing Number\n", .{
                            context.state.number
                        });
                    },

                    // ...
                }

                return error.ParsingFailed;
            },
        }
    };
}
\end{minted}

O altă variantă ar fi putea următoarea, unde octeții citiți
se consumă numai dacă nu s-a observat o eroare.

\begin{minted}{zig}
pub fn impl(context: *Context) !void
{
    // ...

    switch (context.state.action)
    {
        // ...

        .Number =>
        {
            // Citirea unui număr din fluxul de date, dar nu consumăm octeții.
            const number = try pipelines.peekInt(context.sequence());

            // Salvează contextul.
            context.state.number = number.value;

            // Validarea.
            if (number.value == 256)
            {
                return error.CannotBe256;
            }

            // Se consumă octeții.
            number.apply(context);
        },

        // ...
    }
}
\end{minted}

Se mai poate transmite eroarea într-un mod diferit.
Următoarea abordare permite înregistrarea mai multor erori.
Pentru moment, așa ceva nu se folosește, însă tot este o abordare validă.

\begin{minted}{zig}
pub fn impl(context: *Context) !void
{
    // ...

    switch (context.state.action)
    {
        // ...

        .Number =>
        {
            // Citirea unui întreg.
            const number = try pipelines.readInt(context.sequence());

            // Validarea.
            if (number == 256)
            {
                context.state.addError(.{
                    .err = error.CannotBe256,
                    .context = number,
                });
            }
            else
            {
                // Putem folosi sistemul de tipuri pentru a reprezenta faptul că valoarea a fost validată.
                context.state.number = ValidNumber
                {
                    .value = number,
                };
            }
        },

        // ...
    }
}

pub fn callSite()
{
    // ... 

    const errorScope = context.state.errorScope();

    impl(&context);
    catch |err|
    {
        // Aici, doar sunt posibile doar erori legate cu alocarea memoriei și eroarea NotEnoughBytes.
        // ...
    };

    if (errorScope.errorsHappened()) |errors|
    {
        for (errors) |e|
        {
            switch (e.err)
            {
                // ...

                case error.CannotBe256 =>
                {
                    const numberActuallyRead = try coerce(u32, e.context);
                    std.debug.assert(numberActuallyRead == 256);
                },
            }
        }
    }
}
\end{minted}

În varianta finală a aplicației, datele sunt sălvate în noduri înainte de a returna erori.
Din aceasta cauză, ultimul nod care a fost completat mereu conține întregul context al erorii.
Abordarea aceasta este folosită în aplicație, acolo unde este posibil.
La nivel înalt, procesarea erorilor în așa sistem s-ar asemăna cu următoarea.

\begin{minted}{zig}
pub fn impl(context: *Context) !void
{
    // Este creat un nod nou pe stack-ul nodurilor.
    try context.level().pushNode(.{
        .Foo = context.state.action,
    });
    defer context.level().pop();

    switch (context.state.action)
    {
        // ...

        .Number =>
        {
            const number = try pipelines.readInt(context.sequence());

            try context.level().completeNodeWithValue(.{
                .Number = number,
            });

            if (number > 200)
            {
                return error.CannotBeMoreThan200;
            }
        },

        // ...
    }
}

pub fn callSite()
{
    // ... 

    const errorScope = context.state.errorScope();

    impl(&context);
    catch |err|
    {
        switch (err)
        {
            // ...

            .CannotBeMoreThan200 =>
            {
                const lastNodeData = context.getLastCompletedNodeData();
                print("Number {} cannot be more than 200\n", .{ lastNodeData.Number });
            },
        }
    };
}
\end{minted}

Însă s-a hotărât că procesarea explicită a acestora de program nu merită atenția,
deci eroarea este pur și simplu afișată la ecran, terminând parsarea, dar totodată afișând și interfața obișnuită.
Uitându-se la interfață, utilizatorul poate deduce ce a căuzat eroarea, deoarece arborele s-ar termina la acea poziție.

\section{Complicațiile asociate cu citirea chunk-ului \texttt{IDAT}}

Posibilitatea de a putea păstra informațiile despre originea fiecărui "nod",
adică poziția a acestuia absolută din fișier,
precum și posibilitatea de a trata fluxul de date ca unul linear nu sunt direct compatibile
atunci când fluxul de date poate "sări", adică atunci când pozițiile absolute
între diferitele segmente nu sunt consecutive.
Deoarece unul singur nod poate să se afle la marginea a două segmente (potențial mai mult ca două),
ideea că locația fiecărui nod poate fi descrisă de locația lui absolută în fișier și
lungimea lui deja nu se va aplica.

Cu toate că pentru noduri regulare din formatul PNG așa ceva nu este posibil,
chunk-ul \texttt{IDAT} este special în acest sens.
Toate chunk-urile acestea conțin unul singur stream Zlib partajat,
iar parserul PNG se consideră incorect dacă nu realizează corect
orice distribuție a fluxului Zlib între chunk-uri.
Adică parserul PNG nu poate presupune de exemplu că blocul Zlib va termina de fiecare dată
împreună cu chunk-ul \texttt{IDAT} în care se află.
De fapt, este posibilă situația că biții ultimului octet au rămas necitite până la capăt
în primul chunk \texttt{IDAT}, continuându-se în următorul chunk.

Deoarece arborele Huffman din specificația Zlib permit lungimea maximă de 16 biți pentru coduri,
iar programul trebuie să considere aceste coduri ca noduri separate,
și acestea pot să se afle la ofset-uri de biți nealiniate cu granițele octeților,
în cel mai rău caz se poate întâmpla ca unul singur nod să se afle în 3 chunk-uri în același timp.
De exemplu, primul bit poate să se afle la sfârșitul primului chunk,
următoarele 8 biți pot să se afle în întregul următorul chunk, dacă acesta are lungimea 1, ce este posibil,
și atunci se va termina la începutul celui de-al treilea chunk.

Pentru a putea păstra ideea de a putea procesa datele folosind secvențele,
de părca acestea erau consecutive, ar trebui să se include acele părți trecute necitite până la capăt
la începutul secvenței, când se realizează procesarea fluxului Zlib.

Prima problema era că secvența trebuia să se includă doar segmentele din manager de bufer principal,
folosind de către cititor.
De fapt, segmentele erau păstrate ca index-urile în tabloul de segmente, cu un ofset de bază.
Ca să devină posibil de inclus niște segmente dinafara buferilor principali la începutul secvenței,
modul acesta de adresare a fost schimbat la o listă înlănțuită.
Astfel, este posibil să seteze segmentul adăugator ca primul segment din secvență, urmându-l cu
primul segment din secvența inițială, pentru a crea secvența nouă.

Următoarea problema era că implementarea inițială a secvențelor din modulul \texttt{pipelines} presupunea
că toate segmentele care se află între primul și ultimul segment se includ în secvența în întregime.
Însă, secvența poate avea ca prima poziție segmentul inițial la un ofset.
Deoarece el este predestinat să devină al doilea segment după adăugare a primului segment adăugător,
trebuie s-a hotărât să-i miște buferul de început, aplicând ofsetul.

Această soluție nu se simte curată.
Sunt alte abordări puțin mai complicate, dar care potențial vor face implementarea arborelui mai ușoară.
Deoarece acele segmente de început la moment sunt temporare,
nodurile din arbore nu pot să se refere la acestea, iar pozițiile din acestea pot să nu existe în buferi la momentul curent.

Poate o abordare mai bună ar fi ca acele segmente veche să se păstreze în lista buferilor,
pentru a putea să se adreseze la acestea în secvențe,
și ca segmentele din secvențe să-și poată specifica ofseturi,
cu însele date păstrate separat, doar în buferi principali.
Atunci ar trebui să se adauge și un fel de "comsumed position hint" la cititorul,
ca el să păstreze segmentele care încă nu s-au citit până la capăt.

De fapt, așa idee se folosește și în biblioteca \texttt{System.IO.Pipelines} din C\#,
însă la implementarea inițială nu era clar de ce ar fi necesară această abordare.
După ce s-a întâlnit problema care se rezolvă folosind această idee, s-a clarificat și sensul ei.

Problema aceasta s-a rezolvat prin introducerea distincției între nodurile sintactice,
care reprezintă bucățile concrete din fișier, și ale datelor fiecărui nod.
Datele nu au o locație și pot fi partajate prin mai multe noduri.

În plus, a fost realizată o legare între nodurile care sunt într-un fel o singură parte a aceluiași obiect,
printr-o listă semantică dublu înlănțuită, creată între noduri.
Deci, dacă se întâmplă ca unul și același nod se continuă în următorul chunk,
acesta numaidecât va avea și o referință la nodul care îl conținuă,
iar acel nod va avea o legătură înapoi la primul nod.
Aceasta poate fi util pentru a arăta utilizatorului de exemplu poziția nodului de continuare.

Interesant este și faptul că această structură poate fi expresată în mod general, nu doar pentru nodurile din acest chunk.
Datorită acestui fapt implementarea funcționalităților legate cu această proprietate
nu trebuie să țină cont de tipul de nod.


\chapter{Dezvoltarea în WSL}

% 1. Cross-compilation to windows, testing GUI on windows.
% 2. Running GUIs on WSL (I want to try if it works, that would be easier).

\chapter{Construirea arborelui sintactic}

În implementarea inițială a sistemului, arhitectura a fost concepută în așa fel ca
logica de creare a arborelui să fie cu totul independentă de logica citirii datelor din fluxul de date.
S-a conceput ca transmiterea informațiilor despre nodul curent să fie la nivel de starea generală a citirii.
Deci, citirea următorului element din flux de date ar presupune scrierea informațiilor interpretate
într-un câmp prestabilit, în obiectul care reprezintă datele elementul
din fișier care se citește la momentul dat (fie chunk-ul curent), păstrat în starea generală de citire.
După aceasta, codul care construiește arborele sintactic ar detecta care tip de nod a fost citit la cea mai recentă etapă 
(este o altă problemă, descrisă separat mai târziu),
și, în dependența de stare în care se afla parserul înainte de ultima operație de citire,
ar trebui să acceseze exact același câmp în care au fost copiate datele.

Această abordare are mai multe probleme:
\begin{enumerate}
    \item
        Câmpul în care au fost scrise informațiile trebuie să fie sincronizat
        între codul de scriere și codul de citire.
    \item
        Determinarea din care anume câmp trebuie să fie citite datele
        depinde de starea parserului înainte de ultima operație,
        dar nu doar de tipul nodului produs.
        De exemplu, nodurile generate din elementele formatului Zlib pot apărea
        la mai multe chunk-uri \ac{PNG}, dar ar avea același tip de nod.
    \item
        Parserul poate produce doar un singur tip de nod la fiecare operație, deci trebuie
        să fie oprit după fiecare operație de scriere a datelor într-un câmp.
        Mai mult ca aceasta, parserul nu poate să treacă la următoarea stare imediat,
        deoarece aceasta ar putea elimina unele informații necesare pentru a crea următorul nod.
\end{enumerate}

Următoarea problemă este problema detectării tipului curent de nod.
Deoarece arhitectura sistemului s-a conceput în așa fel ca parserul să nu cunoască despre tipuri de noduri,
nu putem transmite aceste informații direct din parser la codul care folosește parserul pentru
a construi arborele sintactic.
Deci, aceste informații trebuie să fie derivate în mod dinamic pe partea
care intepretează informația primită de la parser.
Pentru acest lucru, trebuie să fie posibil de detectat pentru ce stare au fost citite informații
la ultima invocare, sau cel puțin să fie creat nodul înainte de a realiza invocarea.
După invocare, trebuie să se stabilească care noduri pot fi umplute cu informații,
și dacă trebuie să se creeze noduri noi.
Sistemul de gestionare a acestei informații devine destul de complicat,
și necesită ca codul care construiește arborele să cunoască despre semnificațiile stărilor parserului,
deci are loc și duplicarea structurii stărilor.

Aceste probleme nu semnifică că abordarea nu poate fi folosită în practică,
dar provoacă o imperativă de a căuta o soluție alternativă.
Prima idee destul de evidentă este de schimbat puțin arhitectura,
permițând parserului să cunoască unele concepte care țin de noduri sintactice,
dar totuși să lase responsabilitatea de a aranja nodurile în memorie unui modul extern.

Deci, ideea este ca parserul să genereze un flux de noduri,
care să conțină informațiile interpretate,
pe lângă intervalului citit din fișier pentru a genera aceste informații,
și a adâncimii, pentru a putea determina la care nod părinte acesta trebuie să fie atașat.

\chapterConclusionSection{implementation_chapter_title}


\unnumberedChapter{Concluziile Finale și Recomandările}


\newpage
\markpage{usefulStuffEnd}


% Bibliography
\bibliographystyle{plain}
\bibliography{bibliography}
\addcontentsline{toc}{chapter}{\bibname}

% Appendices
\appendix

% Number with arabic numbers instead of Roman
\renewcommand{\thechapter}{\arabic{chapter}}
% Prepend Anexa to section names, center them
\titleformat{\section}[block]{\normalfont\normalsize\bfseries\filcenter}{Anexa \thesection~}{0pt}{}

% Every section on new page
% \newcommand{\sectionbreak}{\clearpage}

% Since we've got just a single chapter in the appedices,
% but which is also the name of the Appendix chapter, it should be omitted.
% Makes little sense, but ok I guess.
\setcounter{chapter}{1}

\unnumberedChapter{Anexe}
% insert appendices here

\end{document}
% vim: fdm=syntax
